{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "pip install pip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Using cached tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.0)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.5.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Installing collected packages: importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 importlib-metadata-6.0.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 opt-einsum-3.3.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 typing-extensions-4.4.0 werkzeug-2.2.2 wheel-0.38.4 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\91990\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cod-2001647       6.4334275E+00 3.7676000E+00 2.7393300E+00 5.4144500E-01 3.2807750E+00    #! label, atEnergy (eV), egap (eV), eps_elec, eps_ion, eps_tot\n",
      "1.0\n",
      "  1.0276490000E+01   1.6515830000E-01   1.6034090000E-01\n",
      "  1.8177520000E+00   6.3141700000E+00  -9.7529960000E-02\n",
      "  1.7348840000E+00   2.1655910000E+00   5.2648280000E+00\n",
      "C   H   O  \n",
      " 16  20   8\n",
      "Direct\n",
      "  6.5026640000E-01   4.7089680000E-01   2.6080420000E-01\n",
      "  3.4973370000E-01   5.2910340000E-01   7.3919490000E-01\n",
      "  7.3005230000E-01   4.5481950000E-01   4.4966410000E-01\n",
      "  2.6994740000E-01   5.4518020000E-01   5.5033570000E-01\n",
      "  7.7831110000E-01   6.7955230000E-01   3.7982460000E-01\n",
      "  2.2168840000E-01   3.2044690000E-01   6.2017700000E-01\n",
      "  8.2780940000E-01   7.9338760000E-01   9.9707780000E-02\n",
      "  1.7219060000E-01   2.0661270000E-01   9.0029430000E-01\n",
      "  8.0927290000E-01   7.3080400000E-01   9.2693020000E-01\n",
      "  1.9072750000E-01   2.6919670000E-01   7.3070180000E-02\n",
      "  7.3529390000E-01   5.4167840000E-01   9.8663720000E-01\n",
      "  2.6470660000E-01   4.5832230000E-01   1.3362200000E-02\n",
      "  5.9591920000E-01   2.5388680000E-01   3.4961940000E-01\n",
      "  4.0408140000E-01   7.4611310000E-01   6.5037940000E-01\n",
      "  8.5171260000E-01   2.5767360000E-01   4.6568120000E-01\n",
      "  1.4828700000E-01   7.4232630000E-01   5.3431850000E-01\n",
      "  5.5758690000E-01   6.0526660000E-01   2.6651880000E-01\n",
      "  4.4241310000E-01   3.9473340000E-01   7.3347970000E-01\n",
      "  6.6479890000E-01   4.1089010000E-01   6.4163860000E-01\n",
      "  3.3520070000E-01   5.8910920000E-01   3.5836080000E-01\n",
      "  6.9348430000E-01   7.9560200000E-01   4.5473270000E-01\n",
      "  3.0651500000E-01   2.0439730000E-01   5.4526840000E-01\n",
      "  8.6162360000E-01   6.4266390000E-01   4.7596020000E-01\n",
      "  1.3837550000E-01   3.5733520000E-01   5.2404220000E-01\n",
      "  8.7874460000E-01   9.3587410000E-01   4.1654300000E-02\n",
      "  1.2125520000E-01   6.4126360000E-02   9.5834840000E-01\n",
      "  8.4708100000E-01   8.2039430000E-01   7.2825370000E-01\n",
      "  1.5291970000E-01   1.7960720000E-01   2.7174730000E-01\n",
      "  8.1006300000E-01   3.9591280000E-01   9.5003180000E-01\n",
      "  1.8993780000E-01   6.0408860000E-01   4.9966590000E-02\n",
      "  6.6360120000E-01   5.9974300000E-01   8.6140340000E-01\n",
      "  3.3639970000E-01   4.0025850000E-01   1.3859500000E-01\n",
      "  5.2445280000E-01   7.4517350000E-02   2.4887060000E-01\n",
      "  4.7554750000E-01   9.2548200000E-01   7.5112900000E-01\n",
      "  3.6516620000E-03   8.8878520000E-02   6.3643110000E-01\n",
      "  9.9634760000E-01   9.1112020000E-01   3.6356920000E-01\n",
      "  5.7204200000E-01   2.0995080000E-01   1.6635350000E-01\n",
      "  4.2795810000E-01   7.9004910000E-01   8.3364580000E-01\n",
      "  5.6956120000E-01   1.3170560000E-01   5.7784420000E-01\n",
      "  4.3043980000E-01   8.6829440000E-01   4.2215440000E-01\n",
      "  8.7564160000E-01   1.2929890000E-01   3.4600770000E-01\n",
      "  1.2435830000E-01   8.7070170000E-01   6.5399050000E-01\n",
      "  9.2810310000E-01   2.3072240000E-01   6.2406180000E-01\n",
      "  7.1895880000E-02   7.6927610000E-01   3.7593910000E-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data_0001.poscar\", 'r')\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reader(i):\n",
    "    with open(i, \"r\") as file:\n",
    "        data = file.readlines()\n",
    "        l = []\n",
    "        for line in data:\n",
    "            word = line.split()\n",
    "            l.append(word)\n",
    "    return(l[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['16', '20', '8'],\n",
       " ['24', '40', '6'],\n",
       " ['20', '36', '4'],\n",
       " ['30', '20', '8'],\n",
       " ['10', '10', '10'],\n",
       " ['20', '32', '2'],\n",
       " ['28', '16', '4'],\n",
       " ['20', '32', '8'],\n",
       " ['10', '18', '4'],\n",
       " ['22', '16', '6'],\n",
       " ['22', '24', '2'],\n",
       " ['16', '28', '8'],\n",
       " ['16', '28', '8'],\n",
       " ['20', '20', '6'],\n",
       " ['20', '18', '8'],\n",
       " ['20', '28', '4'],\n",
       " ['24', '20', '4'],\n",
       " ['16', '24', '8'],\n",
       " ['20', '20', '4'],\n",
       " ['10', '10', '6'],\n",
       " ['14', '24', '12'],\n",
       " ['22', '12', '8'],\n",
       " ['18', '24', '6'],\n",
       " ['16', '24', '8'],\n",
       " ['18', '16', '8'],\n",
       " ['12', '24', '12'],\n",
       " ['16', '40', '4'],\n",
       " ['16', '32', '4'],\n",
       " ['19', '20', '4'],\n",
       " ['18', '20', '6'],\n",
       " ['22', '20', '4'],\n",
       " ['16', '8', '12'],\n",
       " ['16', '24', '8'],\n",
       " ['16', '16', '8'],\n",
       " ['12', '28', '10'],\n",
       " ['20', '16', '4'],\n",
       " ['14', '20', '12'],\n",
       " ['18', '28', '4'],\n",
       " ['16', '24', '8'],\n",
       " ['16', '24', '4'],\n",
       " ['16', '20', '6'],\n",
       " ['11', '12', '5'],\n",
       " ['12', '28', '12'],\n",
       " ['12', '28', '10'],\n",
       " ['16', '32', '4'],\n",
       " ['18', '20', '4'],\n",
       " ['14', '20', '10'],\n",
       " ['16', '14', '10'],\n",
       " ['20', '16', '4'],\n",
       " ['16', '16', '8'],\n",
       " ['16', '24', '4'],\n",
       " ['16', '20', '6'],\n",
       " ['20', '16', '4'],\n",
       " ['12', '28', '12'],\n",
       " ['12', '28', '10'],\n",
       " ['16', '32', '4'],\n",
       " ['18', '20', '4'],\n",
       " ['14', '20', '10'],\n",
       " ['16', '14', '10'],\n",
       " ['20', '16', '4'],\n",
       " ['16', '16', '8'],\n",
       " ['20', '32', '8'],\n",
       " ['28', '16', '8'],\n",
       " ['20', '20', '12'],\n",
       " ['20', '40', '8'],\n",
       " ['23', '34', '3'],\n",
       " ['24', '32', '8'],\n",
       " ['22', '28', '8'],\n",
       " ['24', '14', '4'],\n",
       " ['22', '28', '8'],\n",
       " ['20', '20', '8'],\n",
       " ['4', '4', '8'],\n",
       " ['4', '16', '4'],\n",
       " ['8', '12', '8'],\n",
       " ['6', '8', '8'],\n",
       " ['8', '16', '4'],\n",
       " ['20', '20', '6'],\n",
       " ['8', '8', '8'],\n",
       " ['8', '12', '8'],\n",
       " ['20', '32', '4'],\n",
       " ['6', '8', '8'],\n",
       " ['4', '4', '8'],\n",
       " ['6', '8', '8'],\n",
       " ['20', '12', '6'],\n",
       " ['20', '14', '2'],\n",
       " ['8', '10', '4'],\n",
       " ['20', '20', '8'],\n",
       " ['8', '14', '4'],\n",
       " ['14', '32', '14'],\n",
       " ['20', '16', '8'],\n",
       " ['10', '16', '5'],\n",
       " ['8', '12', '4'],\n",
       " ['6', '8', '4'],\n",
       " ['7', '10', '5'],\n",
       " ['20', '20', '8'],\n",
       " ['20', '12', '8'],\n",
       " ['8', '20', '2'],\n",
       " ['22', '20', '6'],\n",
       " ['20', '28', '4'],\n",
       " ['8', '16', '4'],\n",
       " ['20', '28', '8'],\n",
       " ['6', '8', '4'],\n",
       " ['12', '8', '4'],\n",
       " ['20', '28', '6'],\n",
       " ['20', '12', '16'],\n",
       " ['20', '24', '6'],\n",
       " ['20', '20', '4'],\n",
       " ['20', '24', '6'],\n",
       " ['18', '24', '6'],\n",
       " ['20', '24', '8'],\n",
       " ['18', '28', '12'],\n",
       " ['16', '32', '10'],\n",
       " ['28', '16', '4'],\n",
       " ['18', '24', '8'],\n",
       " ['22', '24', '6'],\n",
       " ['24', '24', '4'],\n",
       " ['18', '32', '6'],\n",
       " ['21', '28', '3'],\n",
       " ['16', '16', '16'],\n",
       " ['18', '24', '6'],\n",
       " ['16', '40', '8'],\n",
       " ['20', '20', '8'],\n",
       " ['16', '24', '12'],\n",
       " ['18', '28', '6'],\n",
       " ['22', '20', '6'],\n",
       " ['22', '16', '8'],\n",
       " ['20', '20', '8'],\n",
       " ['22', '22', '4'],\n",
       " ['16', '28', '12'],\n",
       " ['16', '40', '8'],\n",
       " ['20', '28', '4'],\n",
       " ['16', '24', '12'],\n",
       " ['20', '28', '6'],\n",
       " ['18', '32', '6'],\n",
       " ['16', '32', '8'],\n",
       " ['20', '24', '6'],\n",
       " ['16', '28', '10'],\n",
       " ['24', '22', '4'],\n",
       " ['24', '16', '8'],\n",
       " ['16', '28', '8'],\n",
       " ['16', '28', '8'],\n",
       " ['16', '22', '8'],\n",
       " ['20', '16', '8'],\n",
       " ['18', '28', '6'],\n",
       " ['18', '20', '8'],\n",
       " ['24', '16', '8'],\n",
       " ['16', '32', '8'],\n",
       " ['22', '20', '4'],\n",
       " ['16', '24', '8'],\n",
       " ['24', '16', '6'],\n",
       " ['22', '20', '4'],\n",
       " ['20', '24', '2'],\n",
       " ['22', '24', '4'],\n",
       " ['18', '20'],\n",
       " ['24', '16', '4'],\n",
       " ['26', '20', '2'],\n",
       " ['16', '16', '2'],\n",
       " ['16', '12', '4'],\n",
       " ['26', '20', '2'],\n",
       " ['16', '16', '2'],\n",
       " ['18', '16', '2'],\n",
       " ['18', '16', '2'],\n",
       " ['6', '8', '4'],\n",
       " ['16', '12', '4'],\n",
       " ['6', '4', '6'],\n",
       " ['14', '12', '4'],\n",
       " ['4', '8', '4'],\n",
       " ['16', '8', '6'],\n",
       " ['14', '8', '6'],\n",
       " ['32', '34'],\n",
       " ['42', '28'],\n",
       " ['28', '36'],\n",
       " ['12', '20'],\n",
       " ['32', '28'],\n",
       " ['20', '16'],\n",
       " ['32', '20'],\n",
       " ['8', '8'],\n",
       " ['20', '28'],\n",
       " ['10', '22'],\n",
       " ['24', '48'],\n",
       " ['30', '46'],\n",
       " ['28', '44'],\n",
       " ['32', '28'],\n",
       " ['30', '22'],\n",
       " ['16', '32'],\n",
       " ['20', '36'],\n",
       " ['30', '22'],\n",
       " ['36', '24'],\n",
       " ['22', '42'],\n",
       " ['20', '40'],\n",
       " ['12', '32'],\n",
       " ['8', '20'],\n",
       " ['12', '18'],\n",
       " ['22', '18'],\n",
       " ['18', '26'],\n",
       " ['12', '12'],\n",
       " ['20', '32'],\n",
       " ['16', '28'],\n",
       " ['24', '26'],\n",
       " ['20', '36'],\n",
       " ['24', '24'],\n",
       " ['24', '36'],\n",
       " ['20', '28'],\n",
       " ['4', '8'],\n",
       " ['16', '16'],\n",
       " ['24', '48'],\n",
       " ['36', '72'],\n",
       " ['4', '8', '2'],\n",
       " ['8', '8', '8'],\n",
       " ['4', '8', '4'],\n",
       " ['24', '40', '8'],\n",
       " ['16', '24', '8'],\n",
       " ['20', '32', '8'],\n",
       " ['24', '40', '20'],\n",
       " ['24', '16', '4']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "mydir = \"C:\\\\Users\\\\91990\\\\Downloads\\\\suppl\\\\suppl\\\\data\\\\\"\n",
    "\n",
    "file_list = glob.glob(mydir + \"/*.poscar\")\n",
    "data = []\n",
    "for i in file_list:\n",
    "    data.append(reader(i))\n",
    "data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2\n",
       "0    16  20   8\n",
       "1    24  40   6\n",
       "2    20  36   4\n",
       "3    30  20   8\n",
       "4    10  10  10\n",
       "..   ..  ..  ..\n",
       "210  24  40   8\n",
       "211  16  24   8\n",
       "212  20  32   8\n",
       "213  24  40  20\n",
       "214  24  16   4\n",
       "\n",
       "[215 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df[2] = df[2].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4334275E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0123523E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9708424E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1263336E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.7118758E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6.0919229E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>6.2310028E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>6.1483299E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>6.0748950E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>7.1118166E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0    6.4334275E+00\n",
       "1    6.0123523E+00\n",
       "2    5.9708424E+00\n",
       "3    7.1263336E+00\n",
       "4    6.7118758E+00\n",
       "..             ...\n",
       "210  6.0919229E+00\n",
       "211  6.2310028E+00\n",
       "212  6.1483299E+00\n",
       "213  6.0748950E+00\n",
       "214  7.1118166E+00\n",
       "\n",
       "[215 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_target = []\n",
    "def reader_out(i):\n",
    "    with open(i, \"r\") as file:\n",
    "        data = file.readlines()\n",
    "        l = []\n",
    "        for line in data:\n",
    "            word = line.split()\n",
    "            l.append(word)\n",
    "    return(l[0][1])\n",
    "for i in file_list:\n",
    "    data_target.append(reader_out(i))\n",
    "df_target = pd.DataFrame(data_target)\n",
    "df_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 20.,  8.],\n",
       "       [24., 40.,  6.],\n",
       "       [20., 36.,  4.],\n",
       "       [30., 20.,  8.],\n",
       "       [10., 10., 10.],\n",
       "       [20., 32.,  2.],\n",
       "       [28., 16.,  4.],\n",
       "       [20., 32.,  8.],\n",
       "       [10., 18.,  4.],\n",
       "       [22., 16.,  6.],\n",
       "       [22., 24.,  2.],\n",
       "       [16., 28.,  8.],\n",
       "       [16., 28.,  8.],\n",
       "       [20., 20.,  6.],\n",
       "       [20., 18.,  8.],\n",
       "       [20., 28.,  4.],\n",
       "       [24., 20.,  4.],\n",
       "       [16., 24.,  8.],\n",
       "       [20., 20.,  4.],\n",
       "       [10., 10.,  6.],\n",
       "       [14., 24., 12.],\n",
       "       [22., 12.,  8.],\n",
       "       [18., 24.,  6.],\n",
       "       [16., 24.,  8.],\n",
       "       [18., 16.,  8.],\n",
       "       [12., 24., 12.],\n",
       "       [16., 40.,  4.],\n",
       "       [16., 32.,  4.],\n",
       "       [19., 20.,  4.],\n",
       "       [18., 20.,  6.],\n",
       "       [22., 20.,  4.],\n",
       "       [16.,  8., 12.],\n",
       "       [16., 24.,  8.],\n",
       "       [16., 16.,  8.],\n",
       "       [12., 28., 10.],\n",
       "       [20., 16.,  4.],\n",
       "       [14., 20., 12.],\n",
       "       [18., 28.,  4.],\n",
       "       [16., 24.,  8.],\n",
       "       [16., 24.,  4.],\n",
       "       [16., 20.,  6.],\n",
       "       [11., 12.,  5.],\n",
       "       [12., 28., 12.],\n",
       "       [12., 28., 10.],\n",
       "       [16., 32.,  4.],\n",
       "       [18., 20.,  4.],\n",
       "       [14., 20., 10.],\n",
       "       [16., 14., 10.],\n",
       "       [20., 16.,  4.],\n",
       "       [16., 16.,  8.],\n",
       "       [16., 24.,  4.],\n",
       "       [16., 20.,  6.],\n",
       "       [20., 16.,  4.],\n",
       "       [12., 28., 12.],\n",
       "       [12., 28., 10.],\n",
       "       [16., 32.,  4.],\n",
       "       [18., 20.,  4.],\n",
       "       [14., 20., 10.],\n",
       "       [16., 14., 10.],\n",
       "       [20., 16.,  4.],\n",
       "       [16., 16.,  8.],\n",
       "       [20., 32.,  8.],\n",
       "       [28., 16.,  8.],\n",
       "       [20., 20., 12.],\n",
       "       [20., 40.,  8.],\n",
       "       [23., 34.,  3.],\n",
       "       [24., 32.,  8.],\n",
       "       [22., 28.,  8.],\n",
       "       [24., 14.,  4.],\n",
       "       [22., 28.,  8.],\n",
       "       [20., 20.,  8.],\n",
       "       [ 4.,  4.,  8.],\n",
       "       [ 4., 16.,  4.],\n",
       "       [ 8., 12.,  8.],\n",
       "       [ 6.,  8.,  8.],\n",
       "       [ 8., 16.,  4.],\n",
       "       [20., 20.,  6.],\n",
       "       [ 8.,  8.,  8.],\n",
       "       [ 8., 12.,  8.],\n",
       "       [20., 32.,  4.],\n",
       "       [ 6.,  8.,  8.],\n",
       "       [ 4.,  4.,  8.],\n",
       "       [ 6.,  8.,  8.],\n",
       "       [20., 12.,  6.],\n",
       "       [20., 14.,  2.],\n",
       "       [ 8., 10.,  4.],\n",
       "       [20., 20.,  8.],\n",
       "       [ 8., 14.,  4.],\n",
       "       [14., 32., 14.],\n",
       "       [20., 16.,  8.],\n",
       "       [10., 16.,  5.],\n",
       "       [ 8., 12.,  4.],\n",
       "       [ 6.,  8.,  4.],\n",
       "       [ 7., 10.,  5.],\n",
       "       [20., 20.,  8.],\n",
       "       [20., 12.,  8.],\n",
       "       [ 8., 20.,  2.],\n",
       "       [22., 20.,  6.],\n",
       "       [20., 28.,  4.],\n",
       "       [ 8., 16.,  4.],\n",
       "       [20., 28.,  8.],\n",
       "       [ 6.,  8.,  4.],\n",
       "       [12.,  8.,  4.],\n",
       "       [20., 28.,  6.],\n",
       "       [20., 12., 16.],\n",
       "       [20., 24.,  6.],\n",
       "       [20., 20.,  4.],\n",
       "       [20., 24.,  6.],\n",
       "       [18., 24.,  6.],\n",
       "       [20., 24.,  8.],\n",
       "       [18., 28., 12.],\n",
       "       [16., 32., 10.],\n",
       "       [28., 16.,  4.],\n",
       "       [18., 24.,  8.],\n",
       "       [22., 24.,  6.],\n",
       "       [24., 24.,  4.],\n",
       "       [18., 32.,  6.],\n",
       "       [21., 28.,  3.],\n",
       "       [16., 16., 16.],\n",
       "       [18., 24.,  6.],\n",
       "       [16., 40.,  8.],\n",
       "       [20., 20.,  8.],\n",
       "       [16., 24., 12.],\n",
       "       [18., 28.,  6.],\n",
       "       [22., 20.,  6.],\n",
       "       [22., 16.,  8.],\n",
       "       [20., 20.,  8.],\n",
       "       [22., 22.,  4.],\n",
       "       [16., 28., 12.],\n",
       "       [16., 40.,  8.],\n",
       "       [20., 28.,  4.],\n",
       "       [16., 24., 12.],\n",
       "       [20., 28.,  6.],\n",
       "       [18., 32.,  6.],\n",
       "       [16., 32.,  8.],\n",
       "       [20., 24.,  6.],\n",
       "       [16., 28., 10.],\n",
       "       [24., 22.,  4.],\n",
       "       [24., 16.,  8.],\n",
       "       [16., 28.,  8.],\n",
       "       [16., 28.,  8.],\n",
       "       [16., 22.,  8.],\n",
       "       [20., 16.,  8.],\n",
       "       [18., 28.,  6.],\n",
       "       [18., 20.,  8.],\n",
       "       [24., 16.,  8.],\n",
       "       [16., 32.,  8.],\n",
       "       [22., 20.,  4.],\n",
       "       [16., 24.,  8.],\n",
       "       [24., 16.,  6.],\n",
       "       [22., 20.,  4.],\n",
       "       [20., 24.,  2.],\n",
       "       [22., 24.,  4.],\n",
       "       [18., 20.,  0.],\n",
       "       [24., 16.,  4.],\n",
       "       [26., 20.,  2.],\n",
       "       [16., 16.,  2.],\n",
       "       [16., 12.,  4.],\n",
       "       [26., 20.,  2.],\n",
       "       [16., 16.,  2.],\n",
       "       [18., 16.,  2.],\n",
       "       [18., 16.,  2.],\n",
       "       [ 6.,  8.,  4.],\n",
       "       [16., 12.,  4.],\n",
       "       [ 6.,  4.,  6.],\n",
       "       [14., 12.,  4.],\n",
       "       [ 4.,  8.,  4.],\n",
       "       [16.,  8.,  6.],\n",
       "       [14.,  8.,  6.],\n",
       "       [32., 34.,  0.],\n",
       "       [42., 28.,  0.],\n",
       "       [28., 36.,  0.],\n",
       "       [12., 20.,  0.],\n",
       "       [32., 28.,  0.],\n",
       "       [20., 16.,  0.],\n",
       "       [32., 20.,  0.],\n",
       "       [ 8.,  8.,  0.],\n",
       "       [20., 28.,  0.],\n",
       "       [10., 22.,  0.],\n",
       "       [24., 48.,  0.],\n",
       "       [30., 46.,  0.],\n",
       "       [28., 44.,  0.],\n",
       "       [32., 28.,  0.],\n",
       "       [30., 22.,  0.],\n",
       "       [16., 32.,  0.],\n",
       "       [20., 36.,  0.],\n",
       "       [30., 22.,  0.],\n",
       "       [36., 24.,  0.],\n",
       "       [22., 42.,  0.],\n",
       "       [20., 40.,  0.],\n",
       "       [12., 32.,  0.],\n",
       "       [ 8., 20.,  0.],\n",
       "       [12., 18.,  0.],\n",
       "       [22., 18.,  0.],\n",
       "       [18., 26.,  0.],\n",
       "       [12., 12.,  0.],\n",
       "       [20., 32.,  0.],\n",
       "       [16., 28.,  0.],\n",
       "       [24., 26.,  0.],\n",
       "       [20., 36.,  0.],\n",
       "       [24., 24.,  0.],\n",
       "       [24., 36.,  0.],\n",
       "       [20., 28.,  0.],\n",
       "       [ 4.,  8.,  0.],\n",
       "       [16., 16.,  0.],\n",
       "       [24., 48.,  0.],\n",
       "       [36., 72.,  0.],\n",
       "       [ 4.,  8.,  2.],\n",
       "       [ 8.,  8.,  8.],\n",
       "       [ 4.,  8.,  4.],\n",
       "       [24., 40.,  8.],\n",
       "       [16., 24.,  8.],\n",
       "       [20., 32.,  8.],\n",
       "       [24., 40., 20.],\n",
       "       [24., 16.,  4.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('data.txt', sep='\\t', index = False)\n",
    "predictors_temp = np.loadtxt('data.txt')\n",
    "predictors_temp = np.delete(predictors_temp, 0, 0)\n",
    "predictors_temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.4334275, 6.0123523, 5.9708424, 7.1263336, 6.7118758, 6.0753783,\n",
       "       7.2960613, 6.0965966, 6.00433  , 7.0070503, 6.584506 , 6.1003165,\n",
       "       6.1007396, 6.6433703, 6.7297317, 6.257421 , 6.8810262, 6.2001278,\n",
       "       6.6720965, 6.6447577, 6.0916841, 7.2851352, 6.3333511, 6.2606903,\n",
       "       6.6991189, 6.0150355, 5.6264143, 5.8528694, 6.5995231, 6.5475802,\n",
       "       6.7793642, 7.1770393, 6.1285028, 6.5236122, 5.7863048, 6.9276731,\n",
       "       6.2857366, 6.1143078, 6.231857 , 6.1656946, 6.3644768, 6.5827578,\n",
       "       5.8079428, 5.8144248, 5.7852155, 6.5772081, 6.3024567, 6.8487278,\n",
       "       6.9522231, 6.6233622, 6.1656946, 6.3644768, 6.8209481, 5.8079428,\n",
       "       5.8144248, 5.7852155, 6.5772081, 6.3024567, 6.8487278, 6.9522231,\n",
       "       6.6233622, 6.0987466, 7.3005869, 6.6438923, 5.9085065, 6.1755041,\n",
       "       6.3490594, 6.3583272, 7.3010421, 6.3752237, 6.7011838, 6.6748429,\n",
       "       5.3117868, 6.3469694, 6.4705598, 5.8271033, 6.668479 , 6.6600342,\n",
       "       6.3470051, 6.0719325, 6.4701961, 6.6742804, 6.470287 , 7.2182733,\n",
       "       7.1266103, 6.3878821, 6.7141213, 6.0649127, 5.8260107, 6.7665113,\n",
       "       6.0975094, 6.2000653, 6.3394855, 6.2414112, 6.552663 , 7.0892293,\n",
       "       5.6177476, 6.7608237, 6.2739403, 5.6979604, 6.2076334, 6.3183744,\n",
       "       7.1683856, 6.2779386, 7.1344859, 6.4643872, 6.6727329, 6.4486272,\n",
       "       6.3021636, 6.4422913, 6.1669404, 5.8909409, 7.3586655, 6.3528128,\n",
       "       6.5727474, 6.6541458, 6.0056161, 6.3022356, 6.66293  , 6.3132469,\n",
       "       5.674163 , 6.6075796, 6.1958022, 6.1404649, 6.7689487, 7.0033479,\n",
       "       6.6891421, 6.6679982, 6.0260006, 5.6740536, 6.2421134, 6.2262445,\n",
       "       6.2801052, 6.013759 , 5.8779783, 6.4485672, 5.9731898, 6.7750284,\n",
       "       7.1025522, 6.1005088, 6.1002973, 6.3014994, 6.8602613, 6.1795803,\n",
       "       6.5424634, 7.1092397, 5.8826211, 6.8070163, 6.1932737, 7.1181026,\n",
       "       6.8046902, 6.4142561, 6.5969615, 6.5430833, 7.1054757, 6.9982494,\n",
       "       6.6417978, 6.9898934, 6.9856869, 6.6476801, 6.826573 , 6.8226008,\n",
       "       6.2595966, 6.9729246, 6.9409502, 6.7631028, 5.8383646, 7.3493351,\n",
       "       7.1643052, 6.5854369, 7.2149982, 6.1967654, 6.0156453, 6.8450058,\n",
       "       7.0060929, 7.3426481, 6.2284793, 6.1547775, 5.7099159, 5.8013882,\n",
       "       6.1308329, 6.1088838, 6.8731058, 7.1059492, 5.8176798, 5.9011244,\n",
       "       7.1047184, 7.1923339, 5.8310775, 5.7955882, 5.5021732, 5.5699872,\n",
       "       6.1701496, 6.6430003, 6.1739239, 6.6991251, 6.0758008, 5.9238025,\n",
       "       6.5874633, 5.9376958, 6.7004793, 6.0476163, 6.2617983, 5.8173882,\n",
       "       6.6231043, 5.8092771, 5.8089067, 5.8232104, 6.6186592, 5.8903584,\n",
       "       6.0919229, 6.2310028, 6.1483299, 6.074895 , 7.1118166])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.to_csv('data_target.txt', sep='\\t', index = False)\n",
    "target = np.loadtxt('data_target.txt')\n",
    "target = np.delete(target, 0, 0)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.zeros(3)\n",
    "for i in range(predictors_temp.shape[0]):\n",
    "    fc = predictors_temp[i,0] / np.sum(predictors_temp[i])\n",
    "    fh = predictors_temp[i,1] / np.sum(predictors_temp[i])\n",
    "    fo = predictors_temp[i,2] / np.sum(predictors_temp[i])\n",
    "    temp = np.array([fc, fh, fo])\n",
    "    predictors = np.vstack((predictors, temp))\n",
    "predictors = np.delete(predictors, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "predictors_norm = sc.fit_transform(predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_norm_train, predictors_norm_test, target_train, target_test = train_test_split(predictors_norm, target, test_size=0.20, random_state=8, shuffle=True)\n",
    "n_cols = predictors_norm.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    " \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 28ms/step - loss: 40.1394 - val_loss: 43.4874\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 36.2965 - val_loss: 38.5791\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 32.6522 - val_loss: 34.1042\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 29.3316 - val_loss: 29.7734\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 25.8748 - val_loss: 25.5067\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 22.6410 - val_loss: 21.4782\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 19.5422 - val_loss: 17.5826\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.6437 - val_loss: 13.8877\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 13.7188 - val_loss: 10.5391\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.1394 - val_loss: 7.5547\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.8106 - val_loss: 5.0441\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.1767 - val_loss: 3.0168\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7752 - val_loss: 1.6463\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.7196 - val_loss: 0.8220\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9462 - val_loss: 0.4188\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6074 - val_loss: 0.3090\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4052 - val_loss: 0.3669\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0508 - val_loss: 0.5013\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9552 - val_loss: 0.5797\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8421 - val_loss: 0.6383\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5297 - val_loss: 0.6843\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4758 - val_loss: 0.6963\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3861 - val_loss: 0.6309\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2775 - val_loss: 0.5421\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1263 - val_loss: 0.5031\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9311 - val_loss: 0.4685\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8525 - val_loss: 0.4813\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6512 - val_loss: 0.4556\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6364 - val_loss: 0.3845\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4963 - val_loss: 0.3440\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3456 - val_loss: 0.3248\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3030 - val_loss: 0.3289\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0920 - val_loss: 0.3290\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1397 - val_loss: 0.3271\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0017 - val_loss: 0.3354\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7597 - val_loss: 0.3205\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8312 - val_loss: 0.2839\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7382 - val_loss: 0.2313\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7138 - val_loss: 0.1929\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5568 - val_loss: 0.1835\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6254 - val_loss: 0.1738\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5289 - val_loss: 0.1692\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4727 - val_loss: 0.1686\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4633 - val_loss: 0.1716\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3779 - val_loss: 0.1553\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3790 - val_loss: 0.1343\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3521 - val_loss: 0.0876\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3064 - val_loss: 0.0579\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2550 - val_loss: 0.0489\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2256 - val_loss: 0.0452\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2802 - val_loss: 0.0434\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2502 - val_loss: 0.0402\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2131 - val_loss: 0.0320\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1875 - val_loss: 0.0422\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1813 - val_loss: 0.0456\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1731 - val_loss: 0.0444\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1575 - val_loss: 0.0368\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1655 - val_loss: 0.0279\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1505 - val_loss: 0.0236\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1512 - val_loss: 0.0197\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1225 - val_loss: 0.0178\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1382 - val_loss: 0.0138\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1100 - val_loss: 0.0113\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1328 - val_loss: 0.0068\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1105 - val_loss: 0.0037\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1266 - val_loss: 0.0012\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1114 - val_loss: 5.3403e-04\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0965 - val_loss: 0.0015\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0966 - val_loss: 0.0037\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1098 - val_loss: 0.0036\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1016 - val_loss: 0.0033\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0949 - val_loss: 0.0020\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0741 - val_loss: 1.2966e-04\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0888 - val_loss: 4.9320e-05\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0897 - val_loss: 1.3348e-04\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0817 - val_loss: 7.7128e-04\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0885 - val_loss: 0.0023\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0984 - val_loss: 8.5886e-04\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0630 - val_loss: 3.9802e-04\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0826 - val_loss: 2.2988e-04\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0971 - val_loss: 1.9513e-05\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0711 - val_loss: 4.9604e-04\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0674 - val_loss: 1.9225e-04\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0799 - val_loss: 3.1029e-04\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0770 - val_loss: 7.4043e-05\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0774 - val_loss: 5.0023e-04\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0624 - val_loss: 9.3014e-04\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0694 - val_loss: 0.0036\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0593 - val_loss: 0.0031\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0940 - val_loss: 0.0036\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0731 - val_loss: 0.0020\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0607 - val_loss: 0.0012\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0727 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0776 - val_loss: 6.8426e-04\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0705 - val_loss: 8.6506e-05\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0725 - val_loss: 2.0686e-04\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0629 - val_loss: 5.7684e-05\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0764 - val_loss: 9.7047e-05\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0726 - val_loss: 0.0025\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0676 - val_loss: 0.0100\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0567 - val_loss: 0.0034\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0671 - val_loss: 0.0011\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0592 - val_loss: 0.0025\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0651 - val_loss: 0.0069\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 0.0111\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0586 - val_loss: 0.0114\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0704 - val_loss: 0.0080\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0583 - val_loss: 0.0045\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0039\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0708 - val_loss: 0.0080\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0618 - val_loss: 0.0025\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0526 - val_loss: 0.0030\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0554 - val_loss: 0.0049\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.0073\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0755 - val_loss: 0.0064\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0059\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0867 - val_loss: 0.0028\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0740 - val_loss: 0.0037\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0760 - val_loss: 0.0064\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0559 - val_loss: 0.0120\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0726 - val_loss: 0.0187\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0595 - val_loss: 0.0058\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0617 - val_loss: 0.0010\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0661 - val_loss: 0.0012\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0100\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.0146\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.0099\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0619 - val_loss: 0.0077\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0736 - val_loss: 0.0061\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0079\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.0147\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0633 - val_loss: 0.0066\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0627 - val_loss: 0.0011\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 3.3872e-05\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0606 - val_loss: 4.6802e-04\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0599 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0570 - val_loss: 0.0153\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0712 - val_loss: 0.0210\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0745 - val_loss: 0.0066\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0533 - val_loss: 0.0021\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0737 - val_loss: 0.0062\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0675 - val_loss: 0.0077\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0604 - val_loss: 0.0079\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0649 - val_loss: 0.0028\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 2.3009e-04\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0679 - val_loss: 4.4710e-04\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.0021\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0500 - val_loss: 0.0027\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0691 - val_loss: 0.0079\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0617 - val_loss: 0.0120\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0576 - val_loss: 0.0136\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0496 - val_loss: 0.0094\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0593 - val_loss: 0.0034\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.0024\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0529 - val_loss: 0.0035\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0074\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0110\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0545 - val_loss: 0.0123\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0645 - val_loss: 0.0050\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0544 - val_loss: 0.0019\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.0058\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.0090\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0556 - val_loss: 0.0143\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0051\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 9.8555e-04\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0551 - val_loss: 9.8544e-05\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0500 - val_loss: 0.0013\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0635 - val_loss: 0.0072\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0066\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0582 - val_loss: 0.0041\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0616 - val_loss: 7.5719e-04\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0049\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0547 - val_loss: 0.0190\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0565 - val_loss: 0.0247\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0703 - val_loss: 0.0086\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0594 - val_loss: 0.0024\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0576 - val_loss: 0.0030\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0656 - val_loss: 0.0022\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0580 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0535 - val_loss: 0.0039\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 0.0022\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0522 - val_loss: 0.0095\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0570 - val_loss: 0.0318\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0654 - val_loss: 0.0189\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0531 - val_loss: 0.0057\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.0024\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 6.6790e-04\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0656 - val_loss: 0.0096\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0585 - val_loss: 0.0140\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0536 - val_loss: 0.0023\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0727 - val_loss: 0.0019\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0584 - val_loss: 0.0030\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.0034\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0569 - val_loss: 0.0027\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.0019\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.0032\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0497 - val_loss: 0.0086\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0517 - val_loss: 0.0204\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.0146\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0083\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0483 - val_loss: 0.0086\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0440 - val_loss: 0.0100\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0458 - val_loss: 0.0091\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0553 - val_loss: 0.0032\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0420 - val_loss: 0.0030\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0447 - val_loss: 0.0050\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0516 - val_loss: 0.0137\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0465 - val_loss: 0.0130\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0520 - val_loss: 0.0127\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0090\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.0070\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0702 - val_loss: 0.0046\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0690 - val_loss: 0.0040\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0480 - val_loss: 0.0079\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0562 - val_loss: 0.0123\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0609 - val_loss: 0.0155\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.0149\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0669 - val_loss: 0.0122\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0521 - val_loss: 0.0069\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0051\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0457 - val_loss: 0.0044\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0558 - val_loss: 0.0021\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0068\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0546 - val_loss: 0.0080\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0452 - val_loss: 0.0091\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0536 - val_loss: 0.0134\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0500 - val_loss: 0.0091\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0012\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0574 - val_loss: 0.0011\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0469 - val_loss: 0.0061\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0525 - val_loss: 0.0184\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0557 - val_loss: 0.0169\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0500 - val_loss: 0.0122\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0579 - val_loss: 0.0054\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0512 - val_loss: 0.0027\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.0040\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0481 - val_loss: 0.0148\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0539 - val_loss: 0.0144\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0550 - val_loss: 0.0089\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0558 - val_loss: 0.0150\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0465 - val_loss: 0.0097\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.0013\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 5.2711e-04\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0495 - val_loss: 0.0079\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0563 - val_loss: 0.0230\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0505 - val_loss: 0.0176\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0421 - val_loss: 0.0089\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0554 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0482 - val_loss: 0.0015\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.0041\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0465 - val_loss: 0.0013\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0556 - val_loss: 0.0015\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0025\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0029\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0121\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0583 - val_loss: 0.0071\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0541 - val_loss: 0.0025\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 0.0097\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0502 - val_loss: 0.0084\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.0053\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0614 - val_loss: 0.0082\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0567 - val_loss: 0.0062\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0496 - val_loss: 0.0018\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0511 - val_loss: 0.0058\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0536 - val_loss: 0.0162\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0453 - val_loss: 0.0109\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0065\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0565 - val_loss: 0.0093\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0491 - val_loss: 0.0130\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0510 - val_loss: 0.0089\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0402 - val_loss: 0.0024\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0480 - val_loss: 0.0016\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0464 - val_loss: 0.0057\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0436 - val_loss: 0.0156\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0060\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0525 - val_loss: 0.0077\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0064\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0573 - val_loss: 0.0142\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0485 - val_loss: 0.0058\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0038\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0587 - val_loss: 0.0048\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0616 - val_loss: 0.0240\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0090\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0480 - val_loss: 0.0011\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0506 - val_loss: 0.0023\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0558 - val_loss: 0.0124\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0501 - val_loss: 0.0504\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0612 - val_loss: 0.0295\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0507 - val_loss: 0.0063\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.0065\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - val_loss: 0.0045\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0434 - val_loss: 0.0076\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0499 - val_loss: 0.0086\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0447 - val_loss: 0.0028\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0412 - val_loss: 0.0115\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0435 - val_loss: 0.0215\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0502 - val_loss: 0.0042\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0432 - val_loss: 0.0024\n",
      "Epoch 302/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0444 - val_loss: 0.0034\n",
      "Epoch 303/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0101\n",
      "Epoch 304/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0520 - val_loss: 0.0085\n",
      "Epoch 305/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0398 - val_loss: 0.0038\n",
      "Epoch 306/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0500 - val_loss: 0.0011\n",
      "Epoch 307/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0405 - val_loss: 0.0020\n",
      "Epoch 308/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0390 - val_loss: 0.0087\n",
      "Epoch 309/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0450 - val_loss: 0.0145\n",
      "Epoch 310/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0440 - val_loss: 0.0012\n",
      "Epoch 311/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0534 - val_loss: 0.0016\n",
      "Epoch 312/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.0221\n",
      "Epoch 313/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0491 - val_loss: 0.0254\n",
      "Epoch 314/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0507 - val_loss: 0.0129\n",
      "Epoch 315/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0473 - val_loss: 0.0015\n",
      "Epoch 316/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0676 - val_loss: 0.0072\n",
      "Epoch 317/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0485 - val_loss: 0.0258\n",
      "Epoch 318/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0435 - val_loss: 0.0079\n",
      "Epoch 319/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.0060\n",
      "Epoch 320/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0502 - val_loss: 0.0067\n",
      "Epoch 321/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0488 - val_loss: 0.0132\n",
      "Epoch 322/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0554 - val_loss: 0.0196\n",
      "Epoch 323/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0590 - val_loss: 0.0133\n",
      "Epoch 324/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0373 - val_loss: 0.0064\n",
      "Epoch 325/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0058\n",
      "Epoch 326/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0476 - val_loss: 0.0119\n",
      "Epoch 327/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0484 - val_loss: 0.0056\n",
      "Epoch 328/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0478 - val_loss: 0.0035\n",
      "Epoch 329/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0561 - val_loss: 0.0019\n",
      "Epoch 330/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.0071\n",
      "Epoch 331/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 0.0237\n",
      "Epoch 332/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.0359\n",
      "Epoch 333/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0520 - val_loss: 0.0243\n",
      "Epoch 334/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0464 - val_loss: 0.0054\n",
      "Epoch 335/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0485 - val_loss: 0.0023\n",
      "Epoch 336/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0123\n",
      "Epoch 337/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 0.0206\n",
      "Epoch 338/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0170\n",
      "Epoch 339/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0506 - val_loss: 0.0091\n",
      "Epoch 340/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0014\n",
      "Epoch 341/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0552 - val_loss: 0.0024\n",
      "Epoch 342/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0446 - val_loss: 0.0191\n",
      "Epoch 343/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0187\n",
      "Epoch 344/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0175\n",
      "Epoch 345/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.0143\n",
      "Epoch 346/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0586 - val_loss: 0.0057\n",
      "Epoch 347/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0561 - val_loss: 0.0027\n",
      "Epoch 348/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - val_loss: 0.0267\n",
      "Epoch 349/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0436 - val_loss: 0.0331\n",
      "Epoch 350/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0480 - val_loss: 0.0145\n",
      "Epoch 351/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0079\n",
      "Epoch 352/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0481 - val_loss: 0.0116\n",
      "Epoch 353/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0490 - val_loss: 0.0095\n",
      "Epoch 354/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - val_loss: 0.0060\n",
      "Epoch 355/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0099\n",
      "Epoch 356/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0436 - val_loss: 0.0103\n",
      "Epoch 357/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0464 - val_loss: 7.0846e-04\n",
      "Epoch 358/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0425 - val_loss: 0.0033\n",
      "Epoch 359/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.0039\n",
      "Epoch 360/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0131\n",
      "Epoch 361/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0582 - val_loss: 0.0065\n",
      "Epoch 362/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 7.6591e-04\n",
      "Epoch 363/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0412 - val_loss: 0.0019\n",
      "Epoch 364/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0107\n",
      "Epoch 365/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0106\n",
      "Epoch 366/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0403 - val_loss: 0.0136\n",
      "Epoch 367/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0558 - val_loss: 0.0250\n",
      "Epoch 368/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0478 - val_loss: 0.0078\n",
      "Epoch 369/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0472 - val_loss: 0.0072\n",
      "Epoch 370/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0491 - val_loss: 0.0049\n",
      "Epoch 371/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0603 - val_loss: 0.0104\n",
      "Epoch 372/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0378 - val_loss: 0.0163\n",
      "Epoch 373/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0502 - val_loss: 0.0047\n",
      "Epoch 374/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0402 - val_loss: 0.0019\n",
      "Epoch 375/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0019\n",
      "Epoch 376/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0507 - val_loss: 0.0169\n",
      "Epoch 377/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0138\n",
      "Epoch 378/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0441 - val_loss: 0.0090\n",
      "Epoch 379/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0388 - val_loss: 0.0035\n",
      "Epoch 380/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0557 - val_loss: 0.0020\n",
      "Epoch 381/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0469 - val_loss: 0.0027\n",
      "Epoch 382/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 0.0045\n",
      "Epoch 383/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0445 - val_loss: 0.0065\n",
      "Epoch 384/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 0.0063\n",
      "Epoch 385/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0024\n",
      "Epoch 386/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0515 - val_loss: 0.0028\n",
      "Epoch 387/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0437 - val_loss: 0.0194\n",
      "Epoch 388/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0182\n",
      "Epoch 389/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.0063\n",
      "Epoch 390/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 8.8592e-04\n",
      "Epoch 391/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0534 - val_loss: 0.0045\n",
      "Epoch 392/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0469 - val_loss: 0.0131\n",
      "Epoch 393/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0470 - val_loss: 0.0091\n",
      "Epoch 394/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0532 - val_loss: 0.0022\n",
      "Epoch 395/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0411 - val_loss: 0.0033\n",
      "Epoch 396/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0137\n",
      "Epoch 397/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0526 - val_loss: 0.0076\n",
      "Epoch 398/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0385 - val_loss: 0.0036\n",
      "Epoch 399/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0084\n",
      "Epoch 400/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0443 - val_loss: 0.0148\n",
      "Epoch 401/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.0063\n",
      "Epoch 402/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0491 - val_loss: 3.6924e-04\n",
      "Epoch 403/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0528 - val_loss: 2.3117e-04\n",
      "Epoch 404/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0524 - val_loss: 0.0040\n",
      "Epoch 405/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0477 - val_loss: 0.0109\n",
      "Epoch 406/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0438 - val_loss: 0.0046\n",
      "Epoch 407/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0043\n",
      "Epoch 408/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0487 - val_loss: 0.0153\n",
      "Epoch 409/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0533 - val_loss: 0.0036\n",
      "Epoch 410/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 3.3120e-04\n",
      "Epoch 411/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0075\n",
      "Epoch 412/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0505 - val_loss: 0.0062\n",
      "Epoch 413/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0463 - val_loss: 0.0038\n",
      "Epoch 414/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0011\n",
      "Epoch 415/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - val_loss: 0.0126\n",
      "Epoch 416/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0440 - val_loss: 0.0335\n",
      "Epoch 417/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - val_loss: 0.0097\n",
      "Epoch 418/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0436 - val_loss: 0.0031\n",
      "Epoch 419/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0128\n",
      "Epoch 420/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0081\n",
      "Epoch 421/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.0033\n",
      "Epoch 422/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0461 - val_loss: 0.0019\n",
      "Epoch 423/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0116\n",
      "Epoch 424/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0166\n",
      "Epoch 425/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0473 - val_loss: 0.0035\n",
      "Epoch 426/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0595 - val_loss: 0.0069\n",
      "Epoch 427/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.0102\n",
      "Epoch 428/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0053\n",
      "Epoch 429/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0428 - val_loss: 0.0051\n",
      "Epoch 430/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0027\n",
      "Epoch 431/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0037\n",
      "Epoch 432/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 0.0310\n",
      "Epoch 433/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0470 - val_loss: 0.0465\n",
      "Epoch 434/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0430 - val_loss: 0.0074\n",
      "Epoch 435/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0321 - val_loss: 0.0022\n",
      "Epoch 436/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0072\n",
      "Epoch 437/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0112\n",
      "Epoch 438/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0400 - val_loss: 0.0154\n",
      "Epoch 439/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.0029\n",
      "Epoch 440/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0445 - val_loss: 0.0030\n",
      "Epoch 441/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0484 - val_loss: 0.0100\n",
      "Epoch 442/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0413 - val_loss: 0.0230\n",
      "Epoch 443/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0375 - val_loss: 0.0089\n",
      "Epoch 444/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0041\n",
      "Epoch 445/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0168\n",
      "Epoch 446/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0310\n",
      "Epoch 447/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0453 - val_loss: 0.0113\n",
      "Epoch 448/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.0058\n",
      "Epoch 449/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0415 - val_loss: 0.0018\n",
      "Epoch 450/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0444 - val_loss: 0.0117\n",
      "Epoch 451/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0346\n",
      "Epoch 452/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 453/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0458 - val_loss: 0.0142\n",
      "Epoch 454/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.0013\n",
      "Epoch 455/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0046\n",
      "Epoch 456/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.0221\n",
      "Epoch 457/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0169\n",
      "Epoch 458/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0453 - val_loss: 0.0069\n",
      "Epoch 459/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0267\n",
      "Epoch 460/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0397 - val_loss: 0.0133\n",
      "Epoch 461/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 5.3504e-04\n",
      "Epoch 462/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0445 - val_loss: 0.0026\n",
      "Epoch 463/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0020\n",
      "Epoch 464/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0438 - val_loss: 0.0056\n",
      "Epoch 465/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0115\n",
      "Epoch 466/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0545 - val_loss: 0.0095\n",
      "Epoch 467/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0132\n",
      "Epoch 468/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0447 - val_loss: 0.0160\n",
      "Epoch 469/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0077\n",
      "Epoch 470/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0461 - val_loss: 0.0042\n",
      "Epoch 471/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0458 - val_loss: 0.0078\n",
      "Epoch 472/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0430 - val_loss: 0.0100\n",
      "Epoch 473/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0020\n",
      "Epoch 474/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0571 - val_loss: 0.0021\n",
      "Epoch 475/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0361 - val_loss: 0.0190\n",
      "Epoch 476/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0522 - val_loss: 0.0081\n",
      "Epoch 477/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0516 - val_loss: 0.0041\n",
      "Epoch 478/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0465 - val_loss: 0.0032\n",
      "Epoch 479/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0165\n",
      "Epoch 480/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0514 - val_loss: 0.0110\n",
      "Epoch 481/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0429 - val_loss: 0.0247\n",
      "Epoch 482/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0027\n",
      "Epoch 483/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0011\n",
      "Epoch 484/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0484 - val_loss: 0.0080\n",
      "Epoch 485/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0413 - val_loss: 0.0052\n",
      "Epoch 486/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0057\n",
      "Epoch 487/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0493 - val_loss: 0.0192\n",
      "Epoch 488/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0065\n",
      "Epoch 489/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 7.7411e-04\n",
      "Epoch 490/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0159\n",
      "Epoch 491/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0403 - val_loss: 0.0347\n",
      "Epoch 492/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0078\n",
      "Epoch 493/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0415 - val_loss: 0.0021\n",
      "Epoch 494/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0035\n",
      "Epoch 495/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0397 - val_loss: 0.0134\n",
      "Epoch 496/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0415 - val_loss: 0.0107\n",
      "Epoch 497/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0396 - val_loss: 0.0124\n",
      "Epoch 498/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0432 - val_loss: 0.0136\n",
      "Epoch 499/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0443 - val_loss: 6.5081e-04\n",
      "Epoch 500/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0460 - val_loss: 0.0038\n",
      "Epoch 501/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0403 - val_loss: 0.0080\n",
      "Epoch 502/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0389 - val_loss: 0.0209\n",
      "Epoch 503/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0414 - val_loss: 0.0058\n",
      "Epoch 504/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0452 - val_loss: 0.0023\n",
      "Epoch 505/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0338 - val_loss: 0.0028\n",
      "Epoch 506/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.0039\n",
      "Epoch 507/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0438 - val_loss: 0.0032\n",
      "Epoch 508/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 0.0036\n",
      "Epoch 509/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0452 - val_loss: 0.0039\n",
      "Epoch 510/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0042\n",
      "Epoch 511/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0406 - val_loss: 0.0106\n",
      "Epoch 512/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0411 - val_loss: 0.0187\n",
      "Epoch 513/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0351 - val_loss: 0.0104\n",
      "Epoch 514/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0415 - val_loss: 0.0061\n",
      "Epoch 515/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0357 - val_loss: 0.0085\n",
      "Epoch 516/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.0172\n",
      "Epoch 517/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0505 - val_loss: 0.0021\n",
      "Epoch 518/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0047\n",
      "Epoch 519/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0099\n",
      "Epoch 520/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0088\n",
      "Epoch 521/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0421 - val_loss: 0.0053\n",
      "Epoch 522/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0040\n",
      "Epoch 523/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0018\n",
      "Epoch 524/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0454 - val_loss: 0.0057\n",
      "Epoch 525/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0409 - val_loss: 0.0392\n",
      "Epoch 526/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0121\n",
      "Epoch 527/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0028\n",
      "Epoch 528/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0012\n",
      "Epoch 529/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0078\n",
      "Epoch 530/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0386 - val_loss: 0.0045\n",
      "Epoch 531/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0014\n",
      "Epoch 532/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - val_loss: 0.0017\n",
      "Epoch 533/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 0.0032\n",
      "Epoch 534/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.0286\n",
      "Epoch 535/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0451 - val_loss: 0.0239\n",
      "Epoch 536/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0480 - val_loss: 0.0011\n",
      "Epoch 537/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0036\n",
      "Epoch 538/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0097\n",
      "Epoch 539/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0203\n",
      "Epoch 540/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0441 - val_loss: 0.0029\n",
      "Epoch 541/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0408 - val_loss: 0.0110\n",
      "Epoch 542/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0365\n",
      "Epoch 543/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0345\n",
      "Epoch 544/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 0.0155\n",
      "Epoch 545/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0054\n",
      "Epoch 546/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0061\n",
      "Epoch 547/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0464 - val_loss: 0.0104\n",
      "Epoch 548/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 0.0074\n",
      "Epoch 549/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0466 - val_loss: 0.0073\n",
      "Epoch 550/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0079\n",
      "Epoch 551/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0119\n",
      "Epoch 552/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.0101\n",
      "Epoch 553/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0423 - val_loss: 0.0119\n",
      "Epoch 554/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0059\n",
      "Epoch 555/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0390 - val_loss: 0.0023\n",
      "Epoch 556/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0492 - val_loss: 0.0140\n",
      "Epoch 557/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0402 - val_loss: 0.0292\n",
      "Epoch 558/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0409 - val_loss: 0.0062\n",
      "Epoch 559/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0511 - val_loss: 0.0078\n",
      "Epoch 560/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0411 - val_loss: 0.0051\n",
      "Epoch 561/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 6.8004e-04\n",
      "Epoch 562/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0141\n",
      "Epoch 563/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0115\n",
      "Epoch 564/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0485 - val_loss: 0.0077\n",
      "Epoch 565/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0366 - val_loss: 0.0035\n",
      "Epoch 566/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0016\n",
      "Epoch 567/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0432 - val_loss: 0.0029\n",
      "Epoch 568/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 0.0104\n",
      "Epoch 569/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0415 - val_loss: 0.0149\n",
      "Epoch 570/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0064\n",
      "Epoch 571/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0471 - val_loss: 7.9755e-04\n",
      "Epoch 572/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0392 - val_loss: 0.0052\n",
      "Epoch 573/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0422 - val_loss: 0.0317\n",
      "Epoch 574/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0474 - val_loss: 0.0017\n",
      "Epoch 575/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0401 - val_loss: 0.0022\n",
      "Epoch 576/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0428 - val_loss: 0.0093\n",
      "Epoch 577/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.0226\n",
      "Epoch 578/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0016\n",
      "Epoch 579/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0538 - val_loss: 0.0033\n",
      "Epoch 580/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0196\n",
      "Epoch 581/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0493 - val_loss: 0.0183\n",
      "Epoch 582/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0484 - val_loss: 0.0034\n",
      "Epoch 583/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0461 - val_loss: 0.0012\n",
      "Epoch 584/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0041\n",
      "Epoch 585/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0398 - val_loss: 0.0024\n",
      "Epoch 586/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0014\n",
      "Epoch 587/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0502 - val_loss: 0.0149\n",
      "Epoch 588/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0431 - val_loss: 0.0091\n",
      "Epoch 589/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0329 - val_loss: 0.0011\n",
      "Epoch 590/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0415 - val_loss: 0.0030\n",
      "Epoch 591/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0090\n",
      "Epoch 592/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.0117\n",
      "Epoch 593/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 5.8767e-04\n",
      "Epoch 594/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0422 - val_loss: 0.0126\n",
      "Epoch 595/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0428 - val_loss: 0.0218\n",
      "Epoch 596/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0506 - val_loss: 0.0099\n",
      "Epoch 597/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0470 - val_loss: 0.0036\n",
      "Epoch 598/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0051\n",
      "Epoch 599/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0145\n",
      "Epoch 600/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0404 - val_loss: 0.0047\n",
      "Epoch 601/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0487 - val_loss: 0.0039\n",
      "Epoch 602/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0467 - val_loss: 0.0044\n",
      "Epoch 603/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0382 - val_loss: 0.0223\n",
      "Epoch 604/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.0186\n",
      "Epoch 605/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0019\n",
      "Epoch 606/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0023\n",
      "Epoch 607/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.0218\n",
      "Epoch 608/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0025\n",
      "Epoch 609/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0340 - val_loss: 7.9181e-04\n",
      "Epoch 610/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0047\n",
      "Epoch 611/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0119\n",
      "Epoch 612/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0099\n",
      "Epoch 613/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0427 - val_loss: 0.0045\n",
      "Epoch 614/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0030\n",
      "Epoch 615/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0379 - val_loss: 0.0088\n",
      "Epoch 616/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0397 - val_loss: 0.0103\n",
      "Epoch 617/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - val_loss: 0.0040\n",
      "Epoch 618/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0077\n",
      "Epoch 619/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.0051\n",
      "Epoch 620/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0049\n",
      "Epoch 621/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 0.0011\n",
      "Epoch 622/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.0015\n",
      "Epoch 623/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0045\n",
      "Epoch 624/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0481 - val_loss: 0.0142\n",
      "Epoch 625/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0208\n",
      "Epoch 626/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0427 - val_loss: 0.0023\n",
      "Epoch 627/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0477 - val_loss: 0.0061\n",
      "Epoch 628/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - val_loss: 0.0115\n",
      "Epoch 629/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0049\n",
      "Epoch 630/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0030\n",
      "Epoch 631/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0467 - val_loss: 0.0046\n",
      "Epoch 632/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0077\n",
      "Epoch 633/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.0093\n",
      "Epoch 634/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0025\n",
      "Epoch 635/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0071\n",
      "Epoch 636/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0107\n",
      "Epoch 637/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0369\n",
      "Epoch 638/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0405 - val_loss: 0.0060\n",
      "Epoch 639/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - val_loss: 0.0035\n",
      "Epoch 640/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.0167\n",
      "Epoch 641/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0472 - val_loss: 0.0110\n",
      "Epoch 642/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 0.0181\n",
      "Epoch 643/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0447 - val_loss: 0.0254\n",
      "Epoch 644/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.0238\n",
      "Epoch 645/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0493 - val_loss: 0.0033\n",
      "Epoch 646/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0389 - val_loss: 0.0235\n",
      "Epoch 647/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0106\n",
      "Epoch 648/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0017\n",
      "Epoch 649/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0446 - val_loss: 0.0233\n",
      "Epoch 650/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0344\n",
      "Epoch 651/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0302 - val_loss: 0.0077\n",
      "Epoch 652/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0050\n",
      "Epoch 653/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - val_loss: 0.0013\n",
      "Epoch 654/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0160\n",
      "Epoch 655/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0360 - val_loss: 0.0214\n",
      "Epoch 656/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0308 - val_loss: 0.0017\n",
      "Epoch 657/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0391 - val_loss: 0.0033\n",
      "Epoch 658/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.0137\n",
      "Epoch 659/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0389 - val_loss: 0.0134\n",
      "Epoch 660/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.0085\n",
      "Epoch 661/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0029\n",
      "Epoch 662/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0408 - val_loss: 0.0133\n",
      "Epoch 663/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0410 - val_loss: 0.0030\n",
      "Epoch 664/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0030\n",
      "Epoch 665/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0420 - val_loss: 0.0112\n",
      "Epoch 666/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 1.1669e-04\n",
      "Epoch 667/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0476 - val_loss: 0.0042\n",
      "Epoch 668/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0083\n",
      "Epoch 669/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0164\n",
      "Epoch 670/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0448 - val_loss: 0.0170\n",
      "Epoch 671/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0021\n",
      "Epoch 672/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0324 - val_loss: 8.9690e-04\n",
      "Epoch 673/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0363 - val_loss: 8.7645e-04\n",
      "Epoch 674/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0095\n",
      "Epoch 675/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0278\n",
      "Epoch 676/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0453 - val_loss: 0.0032\n",
      "Epoch 677/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 5.9241e-04\n",
      "Epoch 678/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0379 - val_loss: 0.0120\n",
      "Epoch 679/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0402 - val_loss: 0.0281\n",
      "Epoch 680/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0025\n",
      "Epoch 681/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0442 - val_loss: 0.0033\n",
      "Epoch 682/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0087\n",
      "Epoch 683/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.0288\n",
      "Epoch 684/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0528 - val_loss: 9.2633e-04\n",
      "Epoch 685/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - val_loss: 0.0016\n",
      "Epoch 686/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0085\n",
      "Epoch 687/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0014\n",
      "Epoch 688/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0024\n",
      "Epoch 689/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0138\n",
      "Epoch 690/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0050\n",
      "Epoch 691/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0176\n",
      "Epoch 692/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0071\n",
      "Epoch 693/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 8.0203e-04\n",
      "Epoch 694/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.0035\n",
      "Epoch 695/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0097\n",
      "Epoch 696/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0406 - val_loss: 0.0114\n",
      "Epoch 697/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 5.0584e-04\n",
      "Epoch 698/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0065\n",
      "Epoch 699/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0409 - val_loss: 0.0123\n",
      "Epoch 700/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0048\n",
      "Epoch 701/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0025\n",
      "Epoch 702/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0462 - val_loss: 0.0075\n",
      "Epoch 703/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0230\n",
      "Epoch 704/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0042\n",
      "Epoch 705/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0389 - val_loss: 0.0057\n",
      "Epoch 706/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0396 - val_loss: 0.0201\n",
      "Epoch 707/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.0042\n",
      "Epoch 708/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0400 - val_loss: 0.0034\n",
      "Epoch 709/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0403 - val_loss: 0.0042\n",
      "Epoch 710/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0422 - val_loss: 0.0016\n",
      "Epoch 711/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0430 - val_loss: 0.0037\n",
      "Epoch 712/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0475 - val_loss: 0.0220\n",
      "Epoch 713/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0042\n",
      "Epoch 714/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - val_loss: 0.0108\n",
      "Epoch 715/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 9.8277e-04\n",
      "Epoch 716/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0369 - val_loss: 0.0031\n",
      "Epoch 718/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0012\n",
      "Epoch 719/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0425 - val_loss: 0.0027\n",
      "Epoch 720/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.0102\n",
      "Epoch 721/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0069\n",
      "Epoch 722/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0389 - val_loss: 0.0085\n",
      "Epoch 723/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 7.2446e-04\n",
      "Epoch 724/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0139\n",
      "Epoch 725/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0431 - val_loss: 0.0182\n",
      "Epoch 726/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0380 - val_loss: 0.0011\n",
      "Epoch 727/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - val_loss: 0.0016\n",
      "Epoch 728/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0383 - val_loss: 0.0179\n",
      "Epoch 729/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0421 - val_loss: 0.0021\n",
      "Epoch 730/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0022\n",
      "Epoch 731/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0392 - val_loss: 0.0079\n",
      "Epoch 732/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - val_loss: 0.0050\n",
      "Epoch 733/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0576 - val_loss: 0.0043\n",
      "Epoch 734/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0391 - val_loss: 0.0091\n",
      "Epoch 735/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0372 - val_loss: 0.0050\n",
      "Epoch 736/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.0119\n",
      "Epoch 737/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0396 - val_loss: 0.0082\n",
      "Epoch 738/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0029\n",
      "Epoch 739/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0488 - val_loss: 0.0185\n",
      "Epoch 740/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0398 - val_loss: 0.0020\n",
      "Epoch 741/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0436 - val_loss: 0.0055\n",
      "Epoch 742/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0423 - val_loss: 0.0095\n",
      "Epoch 743/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0034\n",
      "Epoch 744/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0131\n",
      "Epoch 745/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - val_loss: 0.0113\n",
      "Epoch 746/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0022\n",
      "Epoch 747/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0017\n",
      "Epoch 748/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0078\n",
      "Epoch 749/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0373 - val_loss: 0.0147\n",
      "Epoch 750/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0114\n",
      "Epoch 751/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0326 - val_loss: 0.0085\n",
      "Epoch 752/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 1.8303e-05\n",
      "Epoch 753/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0029\n",
      "Epoch 754/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0174\n",
      "Epoch 755/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0380 - val_loss: 0.0365\n",
      "Epoch 756/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0483 - val_loss: 0.0012\n",
      "Epoch 757/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0430 - val_loss: 7.5595e-04\n",
      "Epoch 758/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0351\n",
      "Epoch 759/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - val_loss: 0.0103\n",
      "Epoch 760/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0465 - val_loss: 0.0027\n",
      "Epoch 761/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0444 - val_loss: 0.0058\n",
      "Epoch 762/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0071\n",
      "Epoch 763/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 0.0160\n",
      "Epoch 764/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0026\n",
      "Epoch 765/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0012\n",
      "Epoch 766/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0454 - val_loss: 0.0117\n",
      "Epoch 767/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0425 - val_loss: 0.0101\n",
      "Epoch 768/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0418 - val_loss: 0.0055\n",
      "Epoch 769/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0335 - val_loss: 0.0273\n",
      "Epoch 770/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.0042\n",
      "Epoch 771/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0341 - val_loss: 0.0032\n",
      "Epoch 772/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.0029\n",
      "Epoch 773/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0379 - val_loss: 0.0272\n",
      "Epoch 774/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0496 - val_loss: 0.0072\n",
      "Epoch 775/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0438 - val_loss: 0.0017\n",
      "Epoch 776/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0319 - val_loss: 0.0151\n",
      "Epoch 777/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0089\n",
      "Epoch 778/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0060\n",
      "Epoch 779/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0033\n",
      "Epoch 780/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0242\n",
      "Epoch 781/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.0014\n",
      "Epoch 782/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0490 - val_loss: 8.6950e-04\n",
      "Epoch 783/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0308 - val_loss: 0.0079\n",
      "Epoch 784/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0372 - val_loss: 0.0016\n",
      "Epoch 785/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0071\n",
      "Epoch 786/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0379 - val_loss: 0.0319\n",
      "Epoch 787/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 0.0125\n",
      "Epoch 788/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 6.5867e-04\n",
      "Epoch 789/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 3.1034e-04\n",
      "Epoch 790/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0404 - val_loss: 0.0319\n",
      "Epoch 791/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0033\n",
      "Epoch 792/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0025\n",
      "Epoch 793/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 0.0037\n",
      "Epoch 794/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0371 - val_loss: 0.0066\n",
      "Epoch 795/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0368 - val_loss: 0.0073\n",
      "Epoch 796/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0306 - val_loss: 0.0028\n",
      "Epoch 797/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.0060\n",
      "Epoch 798/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0054\n",
      "Epoch 799/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0351 - val_loss: 0.0022\n",
      "Epoch 800/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0055\n",
      "Epoch 801/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 5.9955e-04\n",
      "Epoch 802/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0056\n",
      "Epoch 803/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0367 - val_loss: 0.0085\n",
      "Epoch 804/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0327 - val_loss: 0.0022\n",
      "Epoch 805/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - val_loss: 0.0151\n",
      "Epoch 806/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0413 - val_loss: 0.0014\n",
      "Epoch 807/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0440 - val_loss: 0.0038\n",
      "Epoch 808/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0503 - val_loss: 0.0060\n",
      "Epoch 809/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - val_loss: 8.8302e-04\n",
      "Epoch 810/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.0046\n",
      "Epoch 811/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0404 - val_loss: 0.0059\n",
      "Epoch 812/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0382 - val_loss: 0.0015\n",
      "Epoch 813/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0484 - val_loss: 0.0011\n",
      "Epoch 814/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0029\n",
      "Epoch 815/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0131\n",
      "Epoch 816/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0457 - val_loss: 0.0100\n",
      "Epoch 817/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0383 - val_loss: 0.0040\n",
      "Epoch 818/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.0154\n",
      "Epoch 819/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0485 - val_loss: 0.0095\n",
      "Epoch 820/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0384 - val_loss: 0.0102\n",
      "Epoch 821/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.0041\n",
      "Epoch 822/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0454 - val_loss: 0.0017\n",
      "Epoch 823/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0257\n",
      "Epoch 824/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0399 - val_loss: 0.0084\n",
      "Epoch 825/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0383 - val_loss: 0.0020\n",
      "Epoch 826/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0393\n",
      "Epoch 827/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0448 - val_loss: 0.0084\n",
      "Epoch 828/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0490 - val_loss: 2.0766e-04\n",
      "Epoch 829/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0311 - val_loss: 0.0037\n",
      "Epoch 830/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.0040\n",
      "Epoch 831/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0294\n",
      "Epoch 832/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - val_loss: 0.0016\n",
      "Epoch 833/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0040\n",
      "Epoch 834/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 835/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0461 - val_loss: 0.0117\n",
      "Epoch 836/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0338 - val_loss: 9.2095e-04\n",
      "Epoch 837/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0385 - val_loss: 0.0230\n",
      "Epoch 838/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0411 - val_loss: 0.0152\n",
      "Epoch 839/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0449 - val_loss: 8.4542e-04\n",
      "Epoch 840/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.0075\n",
      "Epoch 841/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0090\n",
      "Epoch 842/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0429 - val_loss: 0.0041\n",
      "Epoch 843/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0428 - val_loss: 0.0066\n",
      "Epoch 844/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0342 - val_loss: 0.0037\n",
      "Epoch 845/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0012\n",
      "Epoch 846/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0138\n",
      "Epoch 847/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0381 - val_loss: 0.0098\n",
      "Epoch 848/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0391 - val_loss: 0.0067\n",
      "Epoch 849/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0429 - val_loss: 0.0017\n",
      "Epoch 850/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0468 - val_loss: 0.0017\n",
      "Epoch 851/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0194\n",
      "Epoch 852/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0015\n",
      "Epoch 853/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0017\n",
      "Epoch 854/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0051\n",
      "Epoch 855/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0373 - val_loss: 0.0070\n",
      "Epoch 856/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0064\n",
      "Epoch 857/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0411 - val_loss: 0.0092\n",
      "Epoch 858/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - val_loss: 0.0026\n",
      "Epoch 859/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0385 - val_loss: 0.0111\n",
      "Epoch 860/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0153\n",
      "Epoch 861/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0402 - val_loss: 0.0028\n",
      "Epoch 862/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.0022\n",
      "Epoch 863/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0445 - val_loss: 0.0104\n",
      "Epoch 864/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0425 - val_loss: 0.0081\n",
      "Epoch 865/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0359 - val_loss: 0.0016\n",
      "Epoch 866/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0349 - val_loss: 0.0114\n",
      "Epoch 867/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0321 - val_loss: 0.0081\n",
      "Epoch 868/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0060\n",
      "Epoch 869/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0495 - val_loss: 0.0129\n",
      "Epoch 870/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0028\n",
      "Epoch 871/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.0023\n",
      "Epoch 872/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0369 - val_loss: 0.0073\n",
      "Epoch 873/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0446 - val_loss: 0.0010\n",
      "Epoch 874/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0423 - val_loss: 0.0015\n",
      "Epoch 875/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0366 - val_loss: 0.0099\n",
      "Epoch 876/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0439 - val_loss: 0.0020\n",
      "Epoch 877/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0416 - val_loss: 0.0087\n",
      "Epoch 878/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - val_loss: 0.0188\n",
      "Epoch 879/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0463 - val_loss: 0.0020\n",
      "Epoch 880/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0408 - val_loss: 0.0015\n",
      "Epoch 881/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - val_loss: 0.0066\n",
      "Epoch 882/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0060\n",
      "Epoch 883/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0568 - val_loss: 0.0034\n",
      "Epoch 884/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.0017\n",
      "Epoch 885/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0446 - val_loss: 0.0383\n",
      "Epoch 886/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0425 - val_loss: 0.0069\n",
      "Epoch 887/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0026\n",
      "Epoch 888/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0051\n",
      "Epoch 889/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0315 - val_loss: 0.0137\n",
      "Epoch 890/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 2.3834e-04\n",
      "Epoch 891/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0371 - val_loss: 0.0116\n",
      "Epoch 892/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0017\n",
      "Epoch 893/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - val_loss: 0.0024\n",
      "Epoch 894/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0387 - val_loss: 0.0128\n",
      "Epoch 895/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0464 - val_loss: 9.0071e-04\n",
      "Epoch 896/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.0048\n",
      "Epoch 897/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - val_loss: 0.0234\n",
      "Epoch 898/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0317 - val_loss: 0.0023\n",
      "Epoch 899/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.0057\n",
      "Epoch 900/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0286 - val_loss: 0.0164\n",
      "Epoch 901/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0054\n",
      "Epoch 902/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0367 - val_loss: 0.0047\n",
      "Epoch 903/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0394 - val_loss: 0.0159\n",
      "Epoch 904/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0080\n",
      "Epoch 905/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0336 - val_loss: 0.0022\n",
      "Epoch 906/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0452 - val_loss: 7.3804e-04\n",
      "Epoch 907/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0426 - val_loss: 0.0205\n",
      "Epoch 908/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0175\n",
      "Epoch 909/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - val_loss: 0.0020\n",
      "Epoch 910/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0259\n",
      "Epoch 911/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - val_loss: 0.0114\n",
      "Epoch 912/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0409 - val_loss: 5.4828e-04\n",
      "Epoch 913/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0432 - val_loss: 0.0027\n",
      "Epoch 914/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0120\n",
      "Epoch 915/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0456 - val_loss: 0.0110\n",
      "Epoch 916/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0050\n",
      "Epoch 917/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0071\n",
      "Epoch 918/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0440 - val_loss: 0.0064\n",
      "Epoch 919/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0085\n",
      "Epoch 920/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.0338\n",
      "Epoch 921/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0424 - val_loss: 3.6989e-04\n",
      "Epoch 922/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0378 - val_loss: 0.0054\n",
      "Epoch 923/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0419 - val_loss: 0.0025\n",
      "Epoch 924/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0305 - val_loss: 0.0137\n",
      "Epoch 925/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0124\n",
      "Epoch 926/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0391 - val_loss: 0.0047\n",
      "Epoch 927/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0344 - val_loss: 0.0037\n",
      "Epoch 928/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0068\n",
      "Epoch 929/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0103\n",
      "Epoch 930/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0019\n",
      "Epoch 931/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0042\n",
      "Epoch 932/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0024\n",
      "Epoch 933/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0380 - val_loss: 0.0057\n",
      "Epoch 934/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0426 - val_loss: 0.0114\n",
      "Epoch 935/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0367 - val_loss: 0.0042\n",
      "Epoch 936/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0391 - val_loss: 0.0060\n",
      "Epoch 937/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0414 - val_loss: 0.0078\n",
      "Epoch 938/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0328 - val_loss: 0.0093\n",
      "Epoch 939/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0421 - val_loss: 0.0058\n",
      "Epoch 940/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0346 - val_loss: 0.0011\n",
      "Epoch 941/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0435 - val_loss: 0.0092\n",
      "Epoch 942/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0396 - val_loss: 0.0109\n",
      "Epoch 943/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0443 - val_loss: 2.9260e-04\n",
      "Epoch 944/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0414 - val_loss: 0.0358\n",
      "Epoch 945/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 7.2312e-04\n",
      "Epoch 946/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0438 - val_loss: 0.0052\n",
      "Epoch 947/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0052\n",
      "Epoch 948/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0374 - val_loss: 0.0214\n",
      "Epoch 949/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0348 - val_loss: 0.0159\n",
      "Epoch 950/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 0.0028\n",
      "Epoch 951/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0515 - val_loss: 0.0152\n",
      "Epoch 952/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0462 - val_loss: 0.0106\n",
      "Epoch 953/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0059\n",
      "Epoch 954/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0452 - val_loss: 0.0046\n",
      "Epoch 955/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0410 - val_loss: 0.0021\n",
      "Epoch 956/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0117\n",
      "Epoch 957/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0426 - val_loss: 0.0105\n",
      "Epoch 958/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0422 - val_loss: 0.0036\n",
      "Epoch 959/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0410 - val_loss: 0.0038\n",
      "Epoch 960/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0211\n",
      "Epoch 961/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0400 - val_loss: 0.0085\n",
      "Epoch 962/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0314 - val_loss: 3.8030e-04\n",
      "Epoch 963/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0443 - val_loss: 0.0029\n",
      "Epoch 964/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0031\n",
      "Epoch 965/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - val_loss: 0.0102\n",
      "Epoch 966/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0435 - val_loss: 0.0127\n",
      "Epoch 967/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 9.0639e-04\n",
      "Epoch 968/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0402 - val_loss: 0.0061\n",
      "Epoch 969/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0134\n",
      "Epoch 970/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0427 - val_loss: 0.0019\n",
      "Epoch 971/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0313 - val_loss: 0.0100\n",
      "Epoch 972/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0309 - val_loss: 0.0073\n",
      "Epoch 973/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0329 - val_loss: 0.0195\n",
      "Epoch 974/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.0086\n",
      "Epoch 975/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0048\n",
      "Epoch 976/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.0184\n",
      "Epoch 977/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0038\n",
      "Epoch 978/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0029\n",
      "Epoch 979/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0458 - val_loss: 5.6882e-04\n",
      "Epoch 980/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0444 - val_loss: 1.7664e-04\n",
      "Epoch 981/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0463 - val_loss: 0.0188\n",
      "Epoch 982/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0343 - val_loss: 8.6029e-04\n",
      "Epoch 983/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0459 - val_loss: 7.1022e-04\n",
      "Epoch 984/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0399 - val_loss: 0.0059\n",
      "Epoch 985/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0285 - val_loss: 0.0016\n",
      "Epoch 986/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0391 - val_loss: 0.0081\n",
      "Epoch 987/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.0186\n",
      "Epoch 988/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0441 - val_loss: 0.0058\n",
      "Epoch 989/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 7.0353e-04\n",
      "Epoch 990/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.0014\n",
      "Epoch 991/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0314 - val_loss: 0.0070\n",
      "Epoch 992/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0384 - val_loss: 0.0016\n",
      "Epoch 993/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - val_loss: 0.0018\n",
      "Epoch 994/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0350 - val_loss: 0.0048\n",
      "Epoch 995/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0393 - val_loss: 0.0018\n",
      "Epoch 996/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0374 - val_loss: 0.0351\n",
      "Epoch 997/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0021\n",
      "Epoch 998/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 4.3063e-04\n",
      "Epoch 999/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0214\n",
      "Epoch 1000/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0354 - val_loss: 0.0120\n"
     ]
    }
   ],
   "source": [
    "model = regression_model()\n",
    "\n",
    "trial_fit = model.fit(predictors_norm_train, target_train, epochs=1000, verbose=1, validation_split=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x166ed331d90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(trial_fit.history['loss'], label='loss')\n",
    "plt.plot(trial_fit.history['val_loss'], label='val_loss')\n",
    "plt.title(\"Losses vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 995us/step\n"
     ]
    }
   ],
   "source": [
    "test_run = model.predict(predictors_norm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9816362383802211\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.scatter(target_train, test_run)\n",
    "plt.title(\"Actual Train Data vs Predicted Data\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.plot(target, target, 'k-')\n",
    "plt.grid()\n",
    "\n",
    "print(r2_score(target_train, test_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(predictors_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAEWCAYAAACTwaluAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlRUlEQVR4nO3de5wcVZ338c83yUQmF0kQDCQkBFdMQDGBRC4iPhMiRhDIRRTQVWFdEV0Rd5eEi7vKugoIXhbltbKoq7sKRC5JBMQgGIZHEfDJhFtAogiSZAKRSy7kgiSZ3/NHnZ7U9FR3V8909fTl9369+jXd1dVVp/rynTqnTp2SmeGcc2kMGugCOOfqhweGcy41DwznXGoeGM651DwwnHOpeWA451LzwKgwSZdI+slAl8OlJ8kkvTncv0bSv1ZhnWdK+k3W66m0hgsMSe2SNkh6Xcr5q/LBSfqIpC3htl1SV+zxlj4sb2L4og8pMs8lknZIeiXc/iDpakn7lbGedkl/X275KklSW+z9ekXSKklnZbEuMzvHzP49RZkye19in23u+7Fe0u2Sji9jGZl8rxsqMCRNBI4FDDhlYEvTk5ldZ2YjzGwEcAKwLvc4TMvKT81sJLAXMBfYF+goJzRqxLrwPr0euAD4nqRD8mcqFqB1aFTY5inAXcBiSWcOaInMrGFuwBeB+4BvArfnPTceWAS8ALwEXA0cDLwK7AK2ABvDvO3A38deeybwm9jjq4A1wGagAzg29twlwE9KlLMNWBt7PBa4JZTtGeBzseeOAJaHda0HvhmmryYKxi3hdnTCenqVBRgMPAJ8PTweDdwe1r0h3N8/PPfV8N68GtZxdantz1vXkcDzwODYtLnAo8W2rdT7Faa9AJwaPpv7gG+Fz/UrwOuAr4f3aD1wDdAae+184DlgHfB34X18c3juR8BXYvPOBh4OZfwT8L4i78tkoh/2y8Aq4EOx5bwBuDUs53fAv8e/U3nbNjGUaUje9PPD9gwKjy8MZXoFeAKYG6YX+l6/H3golGENcEnZv7GB/pFX8gY8BXwGmAbsAMbk/Ui+BQwH9gDelRQGYVo7xQPjb8MXYAjwz+FHsUehH2mxHwDRXl4HUdgNBd4EPA3MCs/fD3w03B8BHFXsS5W3nsSyAF8GHox9kT8ADANGAjcBSwq9F6W2P2FdfwKOjz2+Cbiw2LaleL/mhs93UvhsdgLnhvK0hs/5VqK9qpHAbcBl4fXvI/rRvS18F66nQGAQBdom4Piw3nHA5ALfkeFEP8KzQjkOA14EDgnPLwRuDPO9Deik/MB4U5h+cHj8QaJ/NoOA04CtwH5FvtdtwKFh/reH92FOOb+xhqmSSHoXcABwo5l1EH1RPxyePoLojZ1vZlvN7FUz63P9zsx+YmYvmdlOM/sG0X+0SX1c3DuAfczsy2b2mpk9DXwPOD08vwN4s6S9zWyLmT3Q13LHrCP6MRG24xYz22ZmrxD99/w/xV5c5vbfAJwBIGkkcGKYBuVt21hJG4l+hF8iCppVue0xs++Y2U6i/6xnA/9oZi+HbbqU3e/nh4AfmtlKM9tKFKqFfAL4bzO7y8y6zKzTzJ4sMO9JwJ/N7IfhfXmIaK/xg5IGE4XyF8P3byXwP0XWW8i68Df32d1kZutC2X4K/JHou57IzNrN7LEw/6NEn0PRzzpfwwQG8HHgl2b2Ynh8fZgGUXXk2fCF6jdJ50v6vaRN4Uu8J7B3Hxd3AOHHkLsBFwNjwvOfAN4CPCnp/0k6qZ/Fh+g/5csAkoZJ+i9Jz0raDPxfYFT4kicqc/uvB+aFRuh5wAoze7YP27bOzEaZ2V5mNtXMFsaeWxO7vw/R3lJH7P1cGqZD9I8jPv+zFDae6B9PGgcAR+Z9jh8hajPah2ivI+16CxkX/uY+u49Jeji2vrdR5Hso6UhJ90h6QdIm4Jxi8ydpiAYiSa1E/zkGS3o+TH4d0Rd/CtEHNUHSkITQSDpddyvRly5n39i6jgUWADOBx82sS9IGQH0s/hrgGTM7KOlJM/sjcIakQUQ/uJslvaFAuUsKyzkZuDtM+meivYMjzex5SVOJ6rm57bG815e1/Wb2hKRniRp6P0wUIEW3LfznL0e8jC8C24G3mllnwrzPEQVBzoQiy10D/E2KdebmvdfMeh3JCOG7M6w3t4dSbL2FzAX+AqySdADRnuhM4H4z2yXpYQp8bsH1RG13J5jZq5L+gzIDo1H2MOYQNfAcAkwNt4OBXwMfI2pkeg64XNJwSXtIOia8dj2wv6ShseU9TPRfcVg4Pv+J2HMjiT78F4Ahkr5I1HLfV78DXpF0gaRWSYMlvU3SOwAk/a2kfcysC9gYXtMV1t9FVK8tSdIQSQcT7YbuS9QwnNue7cBGSXsR7e7Hrc9bR1+2/3rgPODdRG0YuTIV2rY+C8v6HvAtSW8M6xknaVaY5UbgTEmHSBpG7+2N+wFwlqSZkgaF5UwOz+W/L7cDb5H0UUkt4fYOSQeb2S6iBvdLwnfqEHbv/ZYkaYykz4ayXhS2cThRKLwQ5jmLaA8jJ+l7PRJ4OYTFEeyusqfWKIHxcaJ66Wozez53I0rTjxCl7snAm4laztcSNRIBLAMeB56XlKvOfAt4jehN/x/guti67iTaxf0D0W7lq/Tc1SxL+DKdRBRyzxD9h/w+0W4+RI10jyvqq3EVcLqZbTezbUTtDfeFXdKjCqzitPDaTUQNgS8B08wsVx/+D6KGwheBB8K2xV0FnKqob8u3+7j9ubrysliVseC2lVhWGhcQNYA/EKpZdxPaWMzsF0TbvCzMs6zQQszsd0SNmN8iev/uJap6QN77EtpK3kvUVrKOqCH4a0R7ugCfJWrYfZ6oYfWHKbZjo6StwGNEbT8fNLP/DmV7AvgGUcPxeqLGzPtir036Xn8G+LKkV4ga2W9MUYYeFFpPnXOupEbZw3DOVYEHhnMuNQ8M51xqHhjOudTqrh/G3nvvbRMnTqza+rZu3crw4cOrtr4s1Ps2ePmrr6Oj40Uz2yd/et0FxsSJE1m+fHnV1tfe3k5bW1vV1peFet8GL3/1hc52vXiVxDmXmgeGcy41DwznXGoeGM651DwwnHOpeWA451Kru8OqzrnyLHmokyvvXMW6jdsZO6qV+bMmMeewcaVfmMADw7kGtuShTi5a9BjbXtvJC0su5a/vPIOLtr4G0KfQ8CqJcw3syjtXse21nay+4mS2/+F+Nv72Brbv2MWVd64q/eIEHhjONbDODdtYfcXJ3Y/3mXMxAOs29m2cIg8M5xqUmfFsLCwmLLgNKRryc+yo1j4t0wPDuQZkZgwatPvnHQ+L1pbBzJ/Vt6tieGA412Dyw2JRxxr2Hz0MAeNGtXLZvEP9KIlzrndYdHV1IYm5h+9fkeX7HoZzDaJQWFSSB4ZzDaAaYQEeGM7VvWqFBXhgOFfXqhkW4IHhXN2qdliAB4ZzdWkgwgI8MJyrOwMVFuCB4VxdGciwAA8M5+rGQIcFeE9P5+pCX8OikoPngAeGczWvP2Fx0aLH2L5jFwCdG7dz0aLHgL4NngNeJXGupvWnGnLlnau6wyKnP4PngAeGczWrv20WhQbJ6evgOeCB4VxNqkQDZ6FBcvo6eA54YDhXcyp1NGT+rEm0tgzuMa0/g+eAN3o6V1Mqeeg017DpR0mca0BZ9LOYc9i4fgVEPq+SOFcDFq9Y22tYvWp3ykrDA8O5AbZ4xVrmTRvf/XjCgtu4ePFKljzUOYClSuaB4dwAMrNeYSGp3/0lsuKB4dwAKXYpAOhff4mseGA4NwBKhQX0r79EVjwwnKuypOuGDBva84Blf/tLZMUPqzpXRYUOnUqqaH+JrHhgOFclxfpZVLq/RFa8SuJcFdTC4DeVkFlgSJok6eHYbbOkz+fNI0nflvSUpEclHZ5VeZwbKI0SFpBhlcTMVgFTASQNBjqBxXmznQAcFG5HAt8Nf51rCGbGcccd1/24nsMCqlclmQn8ycyezZs+G/hfizwAjJK0X5XK5FwmljzUyTGXL2PiBbc3zJ5FTrUaPU8HbkiYPg5YE3u8Nkx7Lj6TpLOBswHGjBlDe3t7NqVMsGXLlqquLwv1vg31VP6N23fQuWE7p+3fxXkXze2evujnd3LvvfcOYMkqI/PAkDQUOAW4qK/LMLNrgWsBpk+fbm1tbZUpXArt7e1Uc31ZqPdtqKfyH3P5MtZuGMTqK2Z3T7vqx4v5+qNDuO/CtsTXVHqg3ixVYw/jBGCFma1PeK4TGB97vH+Y5lxd6tywjdVXnNz9OOrBuatgN+8sBurNUjXaMM4guToCcCvwsXC05Chgk5k9V2Be52qamfFsr7CI2iwKdfPOYqDeLGW6hyFpOHA88KnYtHMAzOwa4A7gROApYBtwVpblcS4rpc4NmTF5n8TXZTFQb5Yy3cMws61m9gYz2xSbdk0IC8LRkX8ws78xs0PNbHmW5XEuC/lhcfGiRxiUdzTklo7OxPEtshioN0ve09O5fkjqlNW+6kUsb75C1YwsBurNkp9L4lwKSUcyZk8dm9jPopxqRhYD9WbJA8O5EpKOZFx4y6PMPXz/7nninbLGjmqlMyEcClUz6uXEM/AqiXMl5R/JMDNWffXE7sf5PTjrrZpRDt/DcK6EeFXCzHr0s0jq7p1fzRg6eBCXzTu0bvYiivHAcK6EXBUjPyyOvvTugueGxKsZ7e3ttDVAWIBXSZwraf6sSewxZFCPsJj0hTtY8L7JA1iqgeF7GM6VMHvq2B4NnEdfejcL3je5IaoY5fLAcE2t1IlfjTT4TSV4YLimVerELw+L3rwNwzWtYid+eVgk88BwTatQj8zODds8LArwwHBNK6nnZf4p6h4WPXlguKaV3yMzTaesZueNnq5pxXtkrs0bKWtRxxoPiwS+h+Ga3ktbXu01rN7Fi1cmjl/R7DwwXNNa8lAn59/4MKu++v7uabmRsmp5mLyB5FUS17SuWPokf7r8pO7H+cPqrdu4vUfHrj1bW5Bg47YdNT9uRVY8MFxDStOD8/6L39P9OD8sAPZsbenRsWvj9h3dz9X66N5Z8SqJazi5HpydG7dj7P5x59okSg3YCyBAolfHrrhmrLZ4YLiGU04Pzr+58PbEoyEfOWoCG7ft6DU9X62O7p2VVIEhqVVS/Q8X5JpC4R6cW3v14Pz6h6YyqrWle9roYS38x2lT+cqcQ1ON3F2ro3tnpWQbhqSTga8DQ4EDJU0Fvmxmp2RcNuf6JGlMTbMuVl+x+yub65RVbDzN+bMm9WjDyNcow+6VI80exiXAEcBGADN7GDgwsxI510+9e3D2DItdu3al6pQ157BxXDbvUMaNakXAqNYWRg9rQcC4Ua0NM+xeOdIcJdlhZpvy3uD8yy44VzPiPTg7N2ztFRbxakmaZTVbKBSTJjAel/RhYLCkg4DPAb/NtljOJUt7pfM5h43jlCn7MXjw7j2NcsPC9Zbm3TsXeCvwV6KLKm8GPp9hmZxLVOpwaVxXV1ePsJiw4FamfeVu7+7dTyUDw8y2mdkXzOwdZjY93H+1GoVzLi7tlc6TwkIaxIZtO5h/8yMeGv2Q5ijJPSS0WZjZcZmUyLkC0lyCsFBY5OzYZVx55ypvl+ijNG0Y58fu7wF8ANiZTXGcK6zUJQhLhUVOs3W2qqQ0VZKO2O0+M/snoC37ojnXU7FLEOaHxdFfvSsxLKD5OltVUsnAkLRX7La3pFnAnlUom3M95PeLyPWFSDoasuCEg2kZ1LuvRctgNV1nq0pKUyXpIGrDEFFV5BngE1kWyrlC8vtF5O9Z5A6d5ua55NbHu88yHT2shS+d/FZvv+iHkoFhZt6r09WkQmGR452uKq9gYEiaV+yFZrao8sVxLp1SYeGyUWwP4+QizxnggeEGhIfFwCkYGGZ2VjUL4lwa+WFxwIJbOfaK9qYcLm8gpBqiT9L7ibqH75GbZmZfzqpQziVJ6meBBjXtcHkDIc1h1WuA04jOKRHwQeCAjMvlXA+lOmU143B5AyHNHsY7zeztkh41s3+T9A3gF2kWLmkU8H3gbUTtHn9nZvfHnm8DfkZ0qBZgke+5NLeks1Ffn1ANwXtwDog0LUW5T2GbpLHADmC/lMu/ClhqZpOBKcDvE+b5tZlNDTcPiyaWdDbqhbc8wsyZM7vn2bVrF+NGD098/ahhLYnTXeWkCYzbw57ClcAK4M/A9aVeJGlP4N3ADwDM7DUz29jXgrrGl382qllXj4sM5Y6GzJ81iZbBvXtxbnl1p5+JmjGZJQ+eJekOomBYYmZbwrTXAXuY2aaSC47G/rwWeIJo76IDOM/MtsbmaQNuAdYC64DzzezxhGWdDZwNMGbMmGkLFy5MvYH9tWXLFkaMGFG19WWhXrbhsc7dX6uuri4+/7HdXYF+9atf9Th0+sRzm9nV1fu7O3TwICbtOzLbgpapXt7/uBkzZnSY2fT86cUCYzZwOjATaCcaPOfnZvZamhVKmg48ABxjZg9KugrYbGb/Gpvn9UCXmW2RdCJwlZkdVGy506dPt+XLl6cpQkW0t7fT1tZWtfVloV624ZjLl0XVkbwxOP/zuiV8+sOze8x74IU/TxwnUsAzl78/4ZmBUy/vf5ykxMAoWCUxs5+Z2RnARKK9gI8BqyX9UNLxKda5FlhrZg+GxzcDh+etY3Nu78XM7gBaJO2dZoNc45k/axJ7DFGPsJj0hZ+z3+hhveYt1F7h7RjZSjvi1k/NbC7wXmAqsDTF654H1sSuZzKTqHrSTdK+CqMLSzoilOelsrbANYxTpuzXo83i6K/exeUfmNLjuiE5BXaMC053lZFmxK0xwIeIqif7ATcCZ6Zc/rnAdZKGAk8DZ0k6B8DMrgFOBT4taSfR0ZjTrVAdyTW0Yt2929v/2Gv+TduTr0pWaLqrjGInn30SOAOYRFQlmW9mZY0WHq5hkl8Puib2/NXA1eUs0zWevpwbUmr0LZeNYp/K0cBlwHgz+1y5YeFcGn09kazY6FsuO8UaPf/OzO4ys65qFsg1j0Uda3qExdu/+AtufeS5VK8tNPqWn0uSrVQnnzlXaYs61vCB6RO6H09YcCub/rqL+Tc9AqQ7icwHyKk+H0TAVV1XV1evsMidSLajy/wkshpWrNFzr2IvNLOXK18c1+jSXArATyKrXcWqJPHBfycAG8L9UcBq/ArurkxprxviRzpqV7FGzwPN7E3A3cDJZra3mb0BOAn4ZbUK6OrPkoc6OebyZRx44c855vJlLHmos1dY3LJ8NUOHDO712pZBfhmAWpamDeOo0G0bADP7BfDO7Irk6lnyKeqP9jp0Om/aeK48dQqjY125R7W2cOUHp3hDZg1Lc5RknaR/AX4SHn+E6MxS53rpfYq6seqrJ3Y/jvez8KMc9SfNHsYZwD7AYqKRwvcJ05zrJd5gaWasvmL34PNdXV0+unedS3Mho5eB8yQNj49l4VySXJft/LA4+tK7CecZujqWZhDgd0p6gjC8nqQpkv4z85K5uhSdoj6oR1gcsOA21m16tbsB1NWvNG0Y3wJmAbcCmNkjkt6daalc3Zo9dSxzD9+/+/EBC26DsGfhlwOof6kqlGa2Jm/SrsQZXVMzsx5tFAdecHt3WOT45QDqW5o9jDWS3gmYpBbgPJJH/3YNLukSALk9hfywmLDgNgqdteg9OetXmsA4h+hyAeOATqJOW5/JslCu9uT6V+QOmcarF7Onju0VFsUaOL0nZ/1KUyWZZGYfMbMxZvZGM/tb4OCsC+ZqS37/CoiqF1csfbKssPAxK+pbmsD4TspproElVSPMjPsvfk/340JhMVjyMSsaRLGzVY8m6gK+j6R/ij31eqD3SQCuoeUPiZffz6JQWLS2DPaQaCDF9jCGAiOIQmVk7LaZaPBe10TiQ+KlDQvAw6LBFNzDMLN7gXsl/cjMnq1imVwNyv3or1j6ZI9qyMQLbsNIDotxo1o9LBpMmjaM74drqwIgabSkO7MrkqtVs6eO7dVmUSgs/DT1xpQmMPaOX0TZzDYAb8ysRK4mJfWzKFQNEfhp6g0qTWB0SeoegFHSAZB4WUvXoMoJixwPi8aUpuPWF4DfSLqX6J/HsYQrqbvGlx8WR196N+s2vVr0Nd4xq3GlubbqUqKLKP8UWAhMMzNvw2gCi1es7REWizrWsOB9k3tdQCjOO2Y1toKBIWly+Hs40SDA68JtQpjm6ljSuJtxi1esZd608d2PJyy4jYsXrwTocQGh0cNaGNXa4h2zmkSxKsk/A58EvpHwnAHHZVIil7li54XMOWwcZtYrLCR1n2l634XHeSg0qWL9MD4Z/s6oXnFcNRQ6L+TKO1eVPJHMzzRtbsW6hs8r9kIzW1T54rhqKPSj79ywreTREG/QbG7FqiS5vr9vJDqnZFl4PAP4LdGAwK4O5Z8XAr27ey/qWMPFi1f22BPxBk1XrEpyFoCkXwKHmNlz4fF+wI+qUjpXUbkBcDo3bkfs7kyTNLq3JCQVHDDHNac0/TDG58IiWE901MTVkfyGztw1MLsKhAX4dUNcb2kC41fh3JEbwuPTiC6f6OpIUkNnsbBwLkma65J8VtJcIDdS+LVmtjjbYrlKy2/oTGqz8LBwpaTZwwBYAbxiZndLGiZppJm9kmXBXGXFGzqTxrO4ePFKJHkVxBWV5kJGnwRuBv4rTBoHLMmwTK6CljzUyarnX9nd0Flg8Bsf/t+lkeZs1X8AjiEaaQsz+yN+entdyDV0vrYrGvA/v80iv59F58btfmUyV1SawPirmb2WeyBpCH56e12IN3SmHVbvokWPeWi4gtIExr2SLgZaJR0P3ATclmbhkkZJulnSk5J+HwYWjj8vSd+W9JSkR/2ktspaV6TNYtjQ5OYrr5q4YtIExgXAC8BjwKeAO4B/Sbn8q4ClZjYZmELvK6adABwUbmcD3025XJfC2FGtmBnnfXRu97QJC25j/9HDuGzeoQVf5+eLuEKKHiWRNBh4PPzgv1fOgiXtSXQo9kyAUK15LW+22cD/mpkBD4Q9kv3yOoq5Pjr/vW/pddbpsKFDunts5np95vPzRVwhin6rRWaQfgaca2ary1qwNBW4FniCaO+iAzjPzLbG5rkduNzMfhMe/wq4wMyW5y3rbMIoX2PGjJm2cOHCcorSL1u2bGHEiBFVW1+lmBnHHbd7BIKrfryYQRrEXsNbugNh4/YddG7YTlfsOzBIYtzoVka1tlS9zIXU62eQU4/lnzFjRoeZTc+fnqYfxmjgcUm/A7p/7GZ2SonXDSEaqetcM3tQ0lXAhcC/pi9297quJQofpk+fbm1tbeUuos/a29up5voqIX9Yvat+vJhvrowCoLVFXDbvoO7+FsUusFwr6vEziKv38selCYyyf+DBWmCtmT0YHt9MFBhxncD42OP9wzTXR8kD9u7uEp5r1MyFgp8v4spRbDyMPYiu3P5mogbPH5jZzrQLNrPnJa2RNMnMVgEziaoncbcCn5W0EDgS2OTtF32XHxYHLLgNEg6deqOm66tiR0n+B5hOFBYnkDxUXynnAtdJehSYClwq6RxJ54Tn7wCeBp4ialT9TB/W4egdFl1dXYwbPSxxXm/UdH1VrEpyiJkdCiDpB8Dvyl24mT1MFDpx18SeN6KepK4fksJCiq48Fo3VuXvH0AfBcf1RLDB25O6Y2U4/k7E2FQoL2H0xofWrViCo2UZNVz+KBcYUSZvDfRH19Nwc7puZvT7z0rmiioVFzpzDxtG+6Y88c3lblUvnGlGxIfoKX63GDbikK5K96aI7fC/CZSrteBiuikr1jcgPi0lfuKP78oX51xhxrpLSnEviqih3Snrnxu0YuwMgdwZp0p7Fqzu7eizDTyBzWfHAqDHFLjKU1GbxXIELI3tfC5cFD4wak/YiQ7kGzkJ9KryvhcuCB0aNSfqhmxnPFhjde/6sSb2upu59LVxWPDBqzPxZk2gZtPvQaKnRveccNq7H1dT9CuouS36UpMbMOWwc/3bb42zYtiP16N5+ApmrFt/DqEEbC4SFj+7tBpoHRg3ab889ig7Y60dA3EDxwKgxZsb9F7+n+3HS6N5+BMQNFA+MGpLfz+LtX1raKyz8CIgbSN7oWSMKnUhWD0PouebhgVEDSp2i7gHhaoVXSQZYmlPUnasVHhgDyMPC1RsPjAHiYeHqkQfGAPCwcPXKA6PKPCxcPfPAqCIPC1fvPDCqxMPCNQIPjCrwsHCNwgMjYx4WrpF4YGTIw8I1Gg+MjHhYuEbkgZEBDwvXqDwwKszDwjUyD4wK8rBwjc4Do0IWr1jbIyzyR/d2rhF4YFTA4hVrmTdtfPfj3OjeucsbOtcoPDD6ycx6hYWP7u0alQdGP+S3Wfjo3q7ReWD0UamwAB/d2zUeD4w+yA+LRR1rGDa05/CoPrq3a0Q+CHCZCh06leSje7uG54FRBh/d2zU7r5Kk5J2ynPPASMXDwrlIplUSSX8GXgF2ATvNbHre823Az4BnwqRFZvblLMtULg8L53arRhvGDDN7scjzvzazk6pQjrKZGccdd1z3Yw8L1+y8SlKA71k415vMLLuFS88AGwAD/svMrs17vg24BVgLrAPON7PHE5ZzNnA2wJgxY6YtXLgwszJD7z2LZcuW1XVYbNmyhREjRgx0MfrMy199M2bM6MhvQgCiH0dWN2Bc+PtG4BHg3XnPvx4YEe6fCPyx1DKnTZtmWerq6jKigDPAli1blun6quGee+4Z6CL0i5e/+oDllvD7y7RKYmad4e9fgMXAEXnPbzazLeH+HUCLpL2zLFMx5tUQ54rKLDAkDZc0MncfeC+wMm+efRV+kZKOCOV5KasyFeNh4VxpWR4lGQMsDj+6IcD1ZrZU0jkAZnYNcCrwaUk7ge3A6WF3qKo8LJxLJ7PAMLOngSkJ06+J3b8auDqrMqThYeFcek19WNXDwrnyNG1geFg4V76mDAwPC+f6pukCw8PCub5rqsDwsHCuf5omMDwsnOu/pggMDwvnKqPhA8PDwrnKaejA8LBwrrIaNjA8LJyrvIYMDA8L57LRkIExefLk7vseFs5VTkMGxpw5c5g0aZKHhXMV1pCB8bWvfY0nn3zSw8K5CmvIwHDOZcMDwzmXmgeGcy41DwznXGoeGM651DwwnHOpeWA451LzwHDOpZbptVWzIOkF4NkqrnJvoNjV5+tBvW+Dl7/6DjCzffIn1l1gVJuk5ZZ0Udo6Uu/b4OWvHV4lcc6l5oHhnEvNA6O0awe6ABVQ79vg5a8R3obhnEvN9zCcc6l5YDjnUvPACCT9WdJjkh6WtDzh+TZJm8LzD0v64kCUsxBJoyTdLOlJSb+XdHTe85L0bUlPSXpU0uEDVdZCUmxDzX4GkibFyvWwpM2SPp83T81/BqUMGegC1JgZZlasg82vzeykqpWmPFcBS83sVElDgWF5z58AHBRuRwLfDX9rSaltgBr9DMxsFTAVQNJgoBNYnDdbPXwGRfkeRgOQtCfwbuAHAGb2mpltzJttNvC/FnkAGCVpv+qWtLCU21AvZgJ/MrP8Hsk1/Rmk4YGxmwG/lNQh6ewC8xwt6RFJv5D01moWroQDgReAH0p6SNL3JQ3Pm2ccsCb2eG2YVivSbAPU7mcQdzpwQ8L0Wv8MSvLA2O1dZnY40W7jP0h6d97zK4j6108BvgMsqXL5ihkCHA5818wOA7YCFw5skcqWZhtq+TMAIFSlTgFuGuiyZMEDIzCzzvD3L0R1zyPynt9sZlvC/TuAFkl7V72gydYCa83swfD4ZqIfX1wnMD72eP8wrVaU3IYa/wxyTgBWmNn6hOdq/TMoyQMDkDRc0sjcfeC9wMq8efZVuG6BpCOI3ruXql3WJGb2PLBG0qQwaSbwRN5stwIfCy31RwGbzOy5apazmDTbUMufQcwZJFdHoMY/gzT8KElkDLA4fBeHANeb2VJJ5wCY2TXAqcCnJe0EtgOnW211kz0XuC7sEj8NnJVX/juAE4GngG3AWQNV0CJKbUNNfwbhn83xwKdi0+rtMyjKu4Y751LzKolzLjUPDOdcah4YzrnUPDCcc6l5YDjnUvPAaDKS5kgySZNTzPt5SUkngKVd15mSrs6bNlHSWkmD8qY/LCnxRKzwmpVJz7nq8sBoPmcAvwl/S/k8yWeM9pmZ/RlYDRybmxbCa2Ssl6erUR4YTUTSCOBdwCeITpDKTR8s6euSVoZxGs6V9DlgLHCPpHvCfFtirzlV0o/C/ZMlPRhOGrtb0pgSRbkhvv5wf2HYk/i1pBXh9s6Ebeix1yLpdklt4f57Jd0fXntT2F5XQR4YzWU20XgTfwBekjQtTD8bmAhMNbO3A9eZ2beBdURjhMwosdzfAEeFk8YWAgtKzH8jMEdSrqfxaUQh8hfg+HAS4GnAt9NuWDin5F+A94TXLwf+Ke3rXTreNby5nEE0SA1EP+wzgA7gPcA1ZrYTwMxeLnO5+wM/DWM7DAWeKTazma0PbRIzJa0HdprZyjAmxtWSpgK7gLeUUYajgEOA+0IX/6HA/WVuhyvBA6NJSNoLOA44VJIBgwGTNL+MxcTPI9gjdv87wDfN7NZQPbgkxbJy1ZL17D5Z6x/D4ylEe7+vJrxuJz33jHPlEHCXmaVpm3F95FWS5nEq8GMzO8DMJprZeKI9gWOBu4BP5aoIIVwAXgFGxpaxXtLB4QjH3Nj0Pdl9mvbHU5ZnEdGJWKcR7e3klvOcmXUBHyUKtXx/BqZKGiRpPLuHIXgAOEbSm8M2DJdUzh6KS8EDo3mcQe8xJm8J079PdOTiUUmPAB8Oz18LLM01ehINaHM78Fsgflr2JcBNkjpIedHhMPze/cB6M3s6TP5P4OOhDJOJBtHJdx9R0D1B1MaxIizvBeBM4AZJj4Zllzx07MrjZ6s651LzPQznXGoeGM651DwwnHOpeWA451LzwHDOpeaB4ZxLzQPDOZfa/weQge9K4RvY2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.scatter(target_test, predictions)\n",
    "plt.title(\"Actual Test Data vs Predicted Data\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.plot(target_train, target_train, 'k-')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771297061436421\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(target_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAEWCAYAAACTwaluAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA59klEQVR4nO2deXxU5fX/3ychgSCRKChIANHWgqgYFlewhapVqyBSRSn+tItVKoLyrSAoUIq2INhaKS+Kin5r6wKorJa6SwsoWjYBF762iiRhEZAEkECWOb8/7p3J7LlZZrLMeb9e88rc53nuc8+dyf3Ms53ziKpiGIbhhbT6NsAwjMaDCYZhGJ4xwTAMwzMmGIZheMYEwzAMz5hgGIbhGROMBoCITBGRZ+vbjsaMiKwUkdvc98NF5PUkXLOLiKiINEv0tRoKJhgE/tkOiEhzj+V/IiKrE22Xe63+IuITkcPuq0BEForIedWoo0EIkvtwfePeR6GI/EFE0uv6Oqr6nKr+wIM9Cf1cRGS7iJSIyCERKRKRd0VkhIh4eu4aoiClvGCISBfgEkCBQfVrTUx2qmorIBu4EPgUWCUil9avWTXiXPdeLgV+DPwivEBDekDqgIGqmg2cCkwH7gOeql+TaoGqpvQLmAysAf4AvBKW1wlYBOwF9gOzgTOBo0AFcBgocsuuBG4LOvcnwOqg48eAfOAgsB64JChvCvBsDPv6AwVR0mcD66qqH7gSKAXKXHs/dNN/CnwCHAI+B+6Icf3mQBFwdlDaSUAJcDLQFnjFLfM1sApIi1GXAt8OOn7RvY8ubt7PgR3Av9z8n7k2HgBeA04NOvdyHOEsduv4p//zj/LZnwW84dq3B7g/zufSGueB3gUUAg8B6W5eOvAIsM/9zEa6djeLcb/bgcvC0s4HfP7PE7ga2Oh+b/nAlKCyO9z6D7uvi4BvAW/j/D/uA54DcpL1vKR8CwO4BedDfw64QkTaAbhN5VeAL3H+oXOB+ar6CTACeE9VW6lqjsfr/BvIA04EngdeFJEWtbB7EdBLRI6LV7+qvgr8Dljg2nuuW/4r4BrgeBzxeFREeoVfRFWPudcaFpQ8FPinqn4F/AoowBGRdjgPY5X+BiLSHadltzEo+Xs4gnyFiFzr1jXErXsV8IJ7blvXpok4gvVfoG+M62QDbwKvAh2AbwNvxflc/gKUu+V6Aj8AbnPzfoHzmfUE+gDXV3Wf4ajqBzif1yVu0jc4/4M5OOLxSxEZ7OZ91/2b49r4HiDANPdezsT5UZtSXTtqTH3+utf3C+iH8wvT1j3+FBjjvr8Ip2UR8etB2C+Ym7aSOC2MKHUcwGmeQ81aGN1wHszc2tQfVH4JcHeMvMuA/wYdrwFucd9PBZYS1HKIcw3F+SU9gPOQP4TTLe7i5p0eVPYfwM+DjtOAIzhN+1uAtUF5gvMQRrQwcIRuYwx7Qj4XHME7BmQFpQ0D3nHfvw2MCMr7AdVsYbjpa4EHYpzzR+BR932XePW7ZQbHur9EvFK9hXEr8Lqq7nOPn3fTwFHuL1W1vC4uJCL3isgnIlIsIkU4Td+2tagyF+efqagm9YvIVSKyVkS+dsv/ME75d4CWInKBO+aTByx282YC/wFeF5HPRWR8FXb3UtUTVPVbqjpRVX1BeflB708FHnMHC4twuhPi3neH4LLqPDnB5wbTCUecvHAqkAHsCrru4zhdL8Kvi9P6rAm5OPeD+5m+IyJ7RaQYp/Ua73trJyLz3UHjg8Cz8crXNU1pcKlaiEgWTtM6XUR2u8nNgRwRORfnH6OziDSLIhrRmtzfAC2DjtsHXesSYBzOQN9HquoTkQM4D0BNuQ7YoKrfeKg/xF53NuhlnF/qpapaJiJLYtmjqhUishDn13YPzljPITfvEE635Fcicjbwtoj8W1XfqsE9BduZD/xWVZ8LLyQiZ+AIgf9Ygo/DyAdu8nA9f9ljOC3OaD8Uu8Ku0zlGvTFxZ7dyAf8s2/M4YzBXqepREfkjlQIQ7f/sd276Oar6tdt9mV1dO2pKKrcwBuMMXHbH+cXMw+kTrsJ5kD7A+QeZLiLHiUgLEfH3k/cAHUUkM6i+TcAQEWkpIt/GGcDzk43TL94LNBORyThjB9VCHHJF5Nc4/er7Pda/B+gSNJ2XiSOOe4FyEbkKp3kdj+eBG4Hh7nu/TdeIyLfdh7YY5zP1Ra+iWswFJojIWe51WovIDW7e34GzRGSIO6MymiCBDuMV4BQRuUdEmotItohc4OaFfC6qugt4Hfi9iBwvImki8i0R+Z5bfiEwWkQ6isgJQFWtqQBufdcA83G6QVvcrGzga1cszseZOfKzF+ezPD0oLRtnALRYRHKBsV5tqAtSWTBuBf5XVXeo6m7/C0eth+P82g7EGfzagdNHvtE9923gI2C3iPi7M4/ijLrvAZ7BGUT18xrOoNv/4TRjjxK7CR2NDiLiHyn/N3AO0F9V/YuTqqr/RffvfhHZ4LYKRuM8AAdw/kmXxTNAVd/HaUV1wBlf8HMGzqDiYeA9YI6qvlONe4t1vcXAw8B8t+m9FbjKzdsH3IAzTbnftWFNjHoO4cyoDAR2A58BA9zskM/FfX8LjqB+jPPZvASc4uY9ifNZfwhswBl4rYrlInII5/t4AGc27qdB+XcCU90yk3G+E7/tR4DfAmvcLtKFwG+AXjji/HePNtQZ4g6cGIZhVEkqtzAMw6gmJhiGYXjGBMMwDM+YYBiG4ZlGtw6jbdu22qVLl6Rd75tvvuG4446rumADprHfg9mffNavX79PVU8KT290gtGlSxfWrVuXtOutXLmS/v37J+16iaCx34PZn3xEJOoqVuuSGIbhGRMMwzA8Y4JhGIZnGt0YRjTKysooKCjg6NGjdV5369at+eSTT+q83mRSX/fQokULOnbsSEZGRtKvbSSGJiEYBQUFZGdn06VLFxwfqLrj0KFDZGdn12mdyaY+7kFV2b9/PwUFBZx22mlJvbaROJpEl+To0aO0adOmzsXCqDkiQps2bRLS6jPqjyYhGICJRQPEvpMGwuaF8OjZMCXH+bt5YZWnxKLJCIZhGFHYvBCWj0aLdjBkwTds2rYdlo+usWiYYNQB+/fvJy8vj7y8PNq3b09ubm7guLS0NO6569atY/To0VVe4+KLL64TW1euXEnr1q3p2bMnXbt25bvf/S6vvPKKp/PefffdOrHBSCJvTUVLj5A29RCLPy1n6j+PQVkJvDW1RtU1iUHP+qZNmzZs2rQJgClTptCqVSvuvffeQH55eTnNmkX/qPv06UOfPn2qvEZdPqyXXHJJQCQ2bdrE4MGDycrK4tJLY29zsnLlSlq1alVnwmUkBy3KJ23qocDxy0OznDfFBTWqLyVbGEs2FtJ3+tucNv7v9J3+Nks2Ftb5NX7yk58wYsQILrjgAsaNG8cHH3zARRddRM+ePbn44ovZtm0b4DyI11xzDeCIzc9+9jP69+/P6aefzqxZswL1tWrVKlC+f//+XH/99XTr1o3hw4f7o0ezYsUKunXrRu/evRk9enSg3njk5eUxefJkZs92wkIuX76cCy64gJ49e3LZZZexZ88etm/fzty5c3n00UfJy8tj1apVUcsZDQtVJW3qwcCxb3J25bhS6441qjPlWhhLNhYyYdEWSsoqACgsKmHCIie84uCeuXV6rYKCAt59913S09M5ePAgq1atolmzZrz55pvcf//9vPzyyxHnfPrpp7zzzjscOnSIrl278stf/jJiHcPGjRv56KOP6NChA3379mXNmjX06dOHO+64g3/961+cdtppDBs2LKLuWPTq1YuZM2cC0K9fP9auXYuIMG/ePGbMmMHvf/97RowYEdJyOnDgQNRyRv2yZGMhM1/bRuGBI3w5Y2AgPVgsSmjO1m+NwvNem0GknGDMfG1bQCz8lJRVMPO1bXUuGDfccAPp6c7WocXFxdx666189tlniAhlZWVRz7n66qtp3rw5zZs35+STT2bPnj107Bj6a3D++ecH0vLy8ti+fTutWrXi9NNPD6x5GDZsGE888YQnO4PDNBYUFHDjjTeya9cuSktLY66h8FrOSB7+H8MjpeXsCBKL+fNmsnPHnzlF97NT2zCjfChv/PtUpnUqrPb/fMp1SXYWlVQrvTYEuzRPmjSJAQMGsHXrVpYvXx5zfULz5pX7Qaenp1NeHhnt3kuZ6rBx40bOPPNMAEaNGsVdd93Fli1bePzxx2Pa6bWckTymLPsoQiw6j1vO/f/pTt9jszj92HP0K53FMl+/wI9kdUk5weiQk1Wt9LqiuLiY3FxHzf/yl7/Uef1du3bl888/Z/v27QAsWLDA03mbN2/mwQcfZOTIkRF2PvPMM4Fy2dnZHDpUOXgWq5xRPyzZWMiBI6URYiEiVMQI9F2TH8mUE4yxV3QlKyM9JC0rI52xV3RN6HXHjRvHhAkT6NmzZ61bBNHIyspizpw5XHnllfTu3Zvs7Gxat24dteyqVasC06ojR45k1qxZgRmSKVOmcMMNN9C7d2/atq3cUGvgwIEsXrw4MOgZq5xRt3gdoJ/x6qdRxSIeNfmRbHTbDPTp00fDA+h88skngSa1F/wDQzuLSuiQk8XYK7rG7Ms1Jl+Sw4cP06pVK1SVkSNHcsYZZzBmzJh6vYfqfjfRaIwBaIKpqf3hA/Tg/LhNG3JOyP+rqpKWVvnbH00ssjLSq6wnGBFZr6oR8/0pN+gJzmxIXQ9wNgSefPJJnnnmGUpLS+nZsyd33HFHfZtk1AIvA/RexAJg2pBzPP9IxiMlBaOpMmbMGMaMGVPfZhh1RFUD9F7F4oSWGXX2I5lyYxiG0VjIaRk9jkiaCF3ueyVELHw+H//volMjymakC78eeFad2WSCYRgNkCUbCzl8NPrgeLnPF7Ioa9H6fESEhwafwx9vzCM3JwsBcnOymHn9uXXa/bYuiWE0QGa+to0yX+SEhKpGzIY88vr/cV0vZyFfosfnrIVhGA2QaOMX0cRCRBKy6DAWJhh1QG3c2yHSdXzu3Ln89a9/rRPb+vfvT69evejRowfdunXjrrvuoqioqMrzfve739XJ9Y34xFpnEb5GIpZYRCsbQh0GzwETjDrB796+adMmRowYwZgxYwLHmZmZVZ4fLhgjRozglltuqTP75s2bx+bNm9m8eTPNmzfn2muvrfIcE4zE419nUVhUglLpCLlkY2HIAsN4YhF30aEbPIfifECdv7UIngOpKhh1rLrRWL9+Pd/73vfo3bs3V1xxBbt27QJg1qxZdO/enR49enDTTTdFdR2fMmUKjzzyCOC0EO677z7OP/98vvOd77Bq1SoAjhw5wtChQ+nevTvXXXcdF1xwQZU7wmVmZjJjxgx27NjBhx9+CMDgwYPp3bs3Z511VsBZbfz48ZSUlJCXl8fw4cNjljNqR1XrLKYNOYcOrVuEiMWi9fl0PKFlYFAz3uIr3prqBMsJphbBcyAVBz39quv/IP2qC9BjaJ1cQlUZNWoUS5cu5aSTTmLBggU88MADPP3000yfPp0vvviC5s2bU1RURE5OToTr+FtvvRVSX3l5OR988AErVqzgN7/5DW+++SZz5szhhBNO4OOPP2br1q3k5eV5si09PZ1zzz2XTz/9lHPPPZenn36aE088kZKSEs477zx+9KMfMX36dGbPnh0ICgRELdemTZs6+bxSlarWWVyb1yEwmAnO1KmIhKTFJVaQnBoGz4FUFIx4qltHgnHs2DG2bt3K5ZdfDkBFRQWnnHIKAD169GD48OEMHjyYwYMHe6pvyJAhAPTu3TvgXLZ69WruvvtuAM4++2x69Ojh2b5gd4BZs2axePFiAPLz8/nss8+iCoHXcoZ3OuRkURhFNDrkZEUsyvKLRbVo3dHtjkRJryGp1yVJgOqGo6qcddZZgXGMLVu28PrrrwPw97//nZEjR7JhwwbOO+88T45ofnf2unBlr6ioYMuWLZx55pmsXLmSN998k/fee48PP/yQnj17RnVT91rOqB7RHCEBCg8cqb1YAFw6GTLCBkQzspz0GpJ6ghFLXWuhuuE0b96cvXv38t577wHOzmwfffQRPp+P/Px8BgwYwMMPP0xxcTGHDx+OcB33Qt++fVm40Bl7+fjjj9myZUuV55SVlTFhwgQ6depEjx49KC4u5oQTTqBly5Z8+umnrF27NlA2IyMjEOQnXjmj5gzumcuPeoeOP6hqyKKsrg+sYOmmnTW7QI+hMHAWtO4EiPN34KxataRTr0ty6eTQMQyoteqGk5aWxksvvcTo0aMpLi6mvLyce+65h+985zvcfPPNFBcXo6qMHj2anJwcBg4cyPXXX8/SpUv505/+5Okad955J7feeivdu3enW7dunHXWWTHd2W+77TaysrI4duwYl112GUuXLgXgyiuvZO7cuZx55pl07dqVCy+8MHDO7bffTo8ePejVqxdPP/10zHJG7Xjn072B99FmQ46W+2oXDa7H0DrrakOKurezeaEzZlFc4LQsLp0c80NtqO7tFRUVlJWV0aJFC/773/9y2WWXsW3btqjTuObeXr/Es/+08X9HgYGyitnTHw6k3zX+PpbrJYHj3Fp4mNYEc28Ppo5Vtz44cuQIAwYMoKysDFVlzpw5ntZ8GA2LnJYZ9Ct5O0QsfJOzKeEppExY5usHOGs0xizYxD0LNpHuRtFKtohAqgpGEyA7O7vKdRdGw8fn0wixEBFaUsq4ZgtZVtovkOfvC/hD7iUy4n0smsygZ2PrWqUC9p3ER1XZ/JsrA8ch+4YAHWR/lXXUNJhvTWkSgtGiRQv2799v/6ANCFVl//79tGjRor5NaZBErLMIEwuAneptnUsync+aRJekY8eOFBQUsHfv3qoLV5OjR482+n/6+rqHFi1aROyp0hSpToxYiBSL/5k4gRKepCWVjopHNJMZ5d7G2RId8T6YJiEYGRkZCdtIZ+XKlfTs2TMhdSeLpnAPDZXq7qQXbQXn0k07uf8luDd9AR2kcrOhZb5+gQFOoXIMI5hkRLwPpkkIhmHUF9XZSS/Wcu/BPXMZs6AvSyr6RtTvU2X79Ksrt0AsKrFZEsNorFTlQLZkYyF7dh/iJ/e9ErrXadhy73h+JdBwIt0nbNBTRLqKyKag10ERuSesjIjILBH5j4hsFpFeibLHMBJBvJ30Ji7ZwpgFmzhWXhE1Bmcw9bXBVnVJmGCo6jZVzVPVPKA3cARYHFbsKuAM93U78OdE2WMYiSDWgz6g20k8t3YHPlXu/n/XBfL8MTjD8ce/CA7gGzfWRT2RrC7JpcB/VfXLsPRrgb+qMx+6VkRyROQUVd2VJLsMo1b4H+jgWZI/dv+M3A0j+U3mXpo9WOlUWFUMzobS7YhHUnxJRORpYIOqzg5LfwWYrqqr3eO3gPtUdV1YudtxWiC0a9eu9/z58xNusx//9oONmcZ+D43K/pIDULQDVR/fH/4/geRn/vY3isXx58lMT6Nr+4bnnxTMgAED6seXREQygUHAhJrWoapPAE+A43yWTEekxu74BI3/HhqV/Y+ejRbtIG1qZcvi7ef+wBmf/pp+pbMQ4NEb8+gf1JL497LH6bRhJifrXr6Sk8jvNZbzBjXMbS6TsdLzKpzWxZ4oeYVAp6Djjm6aYTRKtCg/RCz8Kzj9y7yHX9g5pNvx72WPc/b6ibRnL2kC7dnL2esn8u9ljyfddi8kQzCGAS/EyFsG3OLOllwIFNv4hdFYUVXSph4MHAcv996pbcjJyuChweeEnNNpw0yyJHQriiwppdOGmYk3uAYktEsiIscBlwN3BKWNAFDVucAK4IfAf3BmUX6aSHsMI1HE9Q1ReNuXxzW9Tok472TdC1Gi752s+xJlaq1IaAtDVb9R1TaqWhyUNtcVC9RhpKp+S1XPCR/sNIzGQIRYLLsHgtdZCFyf/i+Obpgf2KjIz1dyUtQ6v5K2iTC11jQJb1XDqGti7UgWzuINBSFi0eW+5RT+e1lEo6GllHIP8yNc0fN7jaVEQwMflWgm+b3G1sl91DW2NNxIecK9TQd0O4mX1xeGOJStXjyHH7z+Mi1LdgfCOi4uv5ghvSvH7DuPW44idJDo3YkOsj9iDcZ5g+7g3+DOkuzjK2lLfu+GO0tigmGkNNG8TZ9buyPEM3RQ2mqmyjxalriDk8X56LJRDJn0VaBM8PaFO7UtHaOIxk5tE3Up+XmD7gBXINq7r4aKdUmMlCaat2n4UsZxzRbSMmgmQ1VJiyEWADPKh3IkrJtxRDP5Izc1ON+Q6mItDCOl8RKtKriL4UydRi73DmaZrx+UOULTQfZTps2YkXEn/a6+vcEv/a4KEwwjpYnlVh4csMbfxQgXix0TT+OSsug7ki3z9WNZaT9uvrAzl+XsZ8qP+9e98fWAdUmMlCaWt+nwCzsHPEfnZd5MWVrzELE4PKkNMytuBCBdBAGyMtJIc/UjXYSbL+xMn1NPZNvuQ1XOtjQWrIVhpDTRvE3Do1ip/pC0tKmB4x0TT2NC+Y2BPUN8qnwx/eqIuv0Dqnd286Gk1cu2AHWNCYaR2mxeyOCVUxl8tADa+XfB+34gO3xRVudxyyO6IbGC6FQnfF9jwbokRpPD66IrNi909tktzgfU+bt8tJNOpFgsWp9Py8zQ39h4UbGqCt/XGLEWhtGkqFYU77emhm7KDc7xW1PRc26IGrBXRDxvKVBVnM7GiAmG0aSI1Q24Z8EmfrXwQ4Zd0KnSY7S4IGodWpQfIhb3L/qQb9//DypUSRcJrSMOY6/o6opVeSCtIcbprA4mGEaTIl5zv0KVZ9fuAHAe+NYd3e5IJeFTp/cv+pDn3s+PXUcc/C2PPds2IOBpk6OGjo1hGE0KL839Z9fucMY1Lp0MGZXlw8XitPteCRGLYF6IkR7O4J65dG2fzRfTr2bN+O83arEAEwyjiRFtXUU0xizYRJfnj2OK3sGRrFMixOKu8ffhi3N+RYru42tdEqNJEbyuItqAox//4/71kVIqmu0n7cHQsHolPIWUSWCtRTjpEn2FZ1PHWhhGk2Nwz1zWjP8+N1/YOW65QWmrmdFsLsc/WOkr4o+U1VJKGddsYcxzh13QKWZeU8ZaGEaTxT8o6R+kDGds+gKyHiwKHIeE1cOJXzEobbXrRLaPA9oKEThBvkG+6AibJ0MPbzusNxVMMIwmQXgQnD92/4yzPnmUqSW7GZHZhpnlQ1ka1L1QVTo/9EXgOFwsAA7ocUzPmBdwbW8jhysz/Yu8IKVEw7okRqPHv1irsKgEBXoffIOz1k+kZcku0lA6pu1jWsY8BqWtBhyx2BG8MXIUsfCpE5azZVhE7xDcRV6phAmG0egJX6wVHvAGCIxJhItFyaScCLFQhb9VXEYOh6mSGIu/miqeBENEskSk8S5PM5o04Yu1YsXUbM++ELHoPG4595WP4FhGaxRHKIrIZl3vGdz60Muk5XgY2GzdsTamNzqqHMMQkYHAI0AmcJqI5AFTVXVQgm0zDE+E+2xEi6npUyUjysbI646/nObjpwXSc4Dz/AeXTnbGKcL9TfxkZDllUggvLYwpwPlAEYCqbgJOS5hFhlFNwhdrhcfU9KmSHhJWbxkiUrVfR4+hMHAWtO4ECGSd6LwQJ23grJQa8ARvsyRlqloc1s9LzWVuRoMkPAjO+uMv56PuXTjrk0fJPLKLjCCxuOi3b7Dr4DHvfh09hqacKMTDi2B8JCI/BtJF5AxgNPBuYs0yjEqKSsroO/1tdhaVcGurDxiXsSBkf5AlFX1DVnYWFpVww7sdUZ3JjhmVPefO45ax8+AxRJwy/k2FGrt/RzLx0iUZBZwFHMPZVPkgcE8CbTKMAEs2FlJ4oITCohIGpq1mXNkcWpbswh/wpnzpKFYvnhOxDFzVFyIW5ZOy2dhiBIPSVuN3A/HHymjscTaTSZWCoapHVPUBVT1PVfu4748mwzjDmPnaNnzuEx5turRZxVHuYX5IWrhYVEzOJj1NOFEO80jGE4H1GFAZMs/whpdZkneIMmahqt+PUtww6pSdRSXgzm7G24LQTzSxSAsaf8uUcsY1W8iy0spVn405ZF6y8TKGcW/Q+xbAjwgOIWQYCcSJb+EMWsbbghCqFotAnUECU3kNwwteuiTrg15rVPV/gP6JN80wnClT/0MfbQvC8vQW/JGbIsTiy4mnRRULqBQYaPwh85JNlYIhIicGvdqKyBVA6yTYZhgM7plL7glZ5OZksdzXjxkZd3Ik6xT8ayGaXfsnLr52RMRsyCMVN3JMIwPplGozZlY406S5OVlMG3KOzZJUAy9dkvU4YxiC0xX5Avh5Io0yjGBysjJYM76/e3Q18JtA3qL1+fyoT2Xci5fX7WBDfhHPrU2DMvh1s79yohwGgdKMHJoPnMljPYbyWFLvoOlQpWCoqq3qNEIIdyWvr8C24WLRedwyfvXiZhSn9fD9K+6iTU9n2ffEJVt44f18Kp5X0l9Y4TnytxFKTMEQkSHxTlTVRXVvjtHQqda+HwnE5/NFiIVIWmA6L9iudV9+HRJEpzqRv41Q4rUwBsbJU8AEIwVpCNv/+Xw+0tMrxyf8YhGO367dxdGXDb3wfr4JRjWJKRiq+tNkGmI0Dupz+78lGwuZ8Y9PeO+BywNpZZOy2c09zCgfGjVg7043qE40UjXyd23wFKJPRK7GWR7ewp+mqqkVasgA6m/7vyUbC7l34Ub+O72y4etfZ9GRfUzPmAdlRIhGh5wsdhcfjSoOqRr5uzZ4mVadC9yI41MiwA3AqQm2y2igRNv3IxlrGX69ZEtUsfATLcq3365YEb5TNfJ3bfDSwrhYVXuIyGZV/Y2I/B74h5fKRSQHmAecjTPu8TNVfS8ovz+wFGeqFmCRtVwaNuGu5HU9S7Lw6d/T98s5nMI+dtGWNafeSdsuPdk89apAmbJJVa/gzA2yy2/bC+/nV3t/VCMUL4Lhb38eEZEOwH7gFI/1Pwa8qqrXi0gm0DJKmVWqeo3H+owGQPBDWJcsfPr3XPPl9ICDWS77+OH2aWT/vFIIOo9bxm7uoSORS8SLOM45LyeLNeNDXZ0eGnyOCUQd4MW9/RW3pTAT2ABsB56v6iQRaQ18F3gKQFVLVbWopoYaTZ++X84J8Ub1qZL9YKhYiKQxo3wopRr5W3ccJQxKW21LvROIaIyRYhFZgSMMS1T1sJvWHGihqsVVVuzE/nwC+Bg4F2fF6N2q+k1Qmf7Ay0ABsBO4V1U/ilLX7cDtAO3ates9f/788CIJ4/Dhw7Rq1Spp10sEjeYedm5yRslwpk4vvflXgayXX3mVncXH8P+/dpcvSZfI3U/LaEbGKWcnw1rPNJrPP4gBAwasV9U+4enxBONa4CbgUmAlTvCcv6tqnI0aQs7vA6wF+qrq+yLyGHBQVScFlTke8KnqYRH5IfCYqp4Rr94+ffrounXrvJhQJ6xcuZL+/fsn7XqJoLHcQ+Gvv0Wu7IuIwfnq3x7jiptHB1aYFhaV8HnzH5MWZZJDEWRKUfKM9kBj+fyDEZGoghGzS6KqS1V1GNAFpxVwC7BDRP5XRC6PdV4QBUCBqr7vHr8E9Aq7xkF/60VVVwAZItLWyw0ZTY81p97JYV9GiFgcmtSGI1ntgMo9U7dPv5qSZtH9HyXrhKTYmqp48SU5AiwAFohID+AZHPGIdAUMPW+3iOSLSFdV3YbTUvk4uIyItAf2qKqKyPk4ArY/SnVGEybQcjjwHW6cUfn175h0Giu6jOTkNu1Cyu0sKmFji8juiJF4vETcagcMxemenAIsBH7isf5RwHPuDMnnwE9FZASAqs4Frgd+KSLlOLMxN2msPpLRJPH7phwpLQtxUT/j/ldYf10eQ3vmsnLlyggfluP1UGC8I4SSA0myPDWJ53z2C2AY0BWnSzJWVasVLdzdwyS8HzQ3KH82MLs6dRpNi5mvbYsQi87jllFaAb968UPA2Vwo3IclVvStVNuJLNnEm1a9CJgGdFLV0dUVC8PwQuGBbyLEwu9IVuHTQIDecF+VaNG3UnEnsmQTz/nsZ8k0xEgNgschbmn5Pl/OeDCQ99XEU3iw4t0QfxBHKI6L8GFZ5usHZXB/5ou0Z19gjxLbdCixeHI+M4zaMnHJFp5buyPgOTpQVjH11w8H8h3fkG+YmfZ4iBOZ36lt7BVdQ8YwAN5I/x7fv/YuC7GXRDzt3m4YtWHiki08GyQWqj5mTw8XC2cEs7lUBJzI0tMksGpzcM9cpg05h9ycLASLx1lfxBv0PDHeiar6dd2bYzRFnn+/MtqVl60AOsh+jstM57fXOYKwcuVnQOJ8WAzvxOuSBAf/7QwccN/nADuwHdwNDyzZWIjPbVp43TckLacjH425MlkmGtUg3qDnaQAi8iSw2F2JiYhcBQxOinVGgydqQOD0NfDWVLS4gPO0DYPShrK04uIQsbhr/H2U8ySZ4XtipWXYTEcDxssYxoV+sQBQ1X8AFyfOJKOx4F9MVeiGwSssKmH14jmULx0FxfkISq7sY1qzJyOmTpfrJdxbdjtfa5BTVtaJMHiOzXQ0YLzMkuwUkYnAs+7xcBzPUiPFiRYQ+B7m06yiMuiuqtIqios6ODMh67Muj4hdYTRcvLQwhgEnAYtxIoWf5KYZKU60wL/BGyarKmlBjmSdxy0Pie5t2xQ2Prw4n30N3C0ixwXHsjCMaAGB/Uu2w8Vix8TTuKSscoAzXcSmRRshXoIAXywiHwOfuMfnisichFtmNHiiBQSeUT6Ub3wZIWJRPimb3LT9rM4czaC01YATTcvEovHhpUvyKHAFrtu5qn6IE3rPSGH8syPhYxhLK/qGjFmUT8omPU1IE+iY5mwHMChtdcK3JTASg6el4aqaL6Hz5RWxyhpNn3BXcz+qyo4ZlVsBlE5qTXpaaLQC/3YA6664Kym2GnWLF8HIF5GLARWRDOBu3O6JkTos2VjIpr8/wW2lzzJI9tFH2jIjrXK3sXCx8E3ORiR6aJMOst+6I40UL12SEcBIIBcoBPKAOxNok9HAWLKxkNWL5zCubA4d0/ZFdC+ii0XsXcV2S5tkmG0kAC+C0VVVh6tqO1U9WVVvBs5MtGFGw2Hma9u4h/khWwCA070Ym76gWmJxRDMp7DUuYbYaicWLYPzJY5rRRCksKglZX+FHVen80BeB41hiUa5p+FTYzUl81Pshzht0R0LtNRJHPG/Vi3CWgJ8kIv8TlHU8VQQANpoOSzYWIkSGxAtfZxFLLEqlOZlDZkOPobQH2ifBZiNxxGthZAKtcEQlO+h1ECd4r5ECzHxtG0poSDyvYgGQed1s8w1pQsTzVv0n8E8R+YuqfplEm4x6IprnqX/5tz8k3tj0BSHdkLJJxxNzyKJ1JxOLJoaXMYx57t6qAIjICSLyWuJMMuqDaJ6nExZtoWVmZe9zaUXfiDGLZjH+g45purmpN0G8CEbb4E2UVfUAcHLCLDLqhWirNkvKKvim1EmrztRphcK0jFHWumiCeBEMn4h09h+IyKmAbTbUxIjmeeqnuussBCHv6tvr1D6jYeBlpecDwGoR+SdOiL5LcHdSN5oO0TxPIVIsdkw8DZH4u1kWZ55sKzmbKFW2MFT1VZxNlBcA84HeqmpjGE2MaJ6nA2VViFjcNf4+ZlbcGLmBUBBHNJPH1MKlNFViCoaIdHP/9sIJArzTfXV204zGzOaF8OjZMCUHHj2bwelrmDbknED2QFkVshWAb3I2D2c+BcCEstso1Lb4VPhaW7Hf1wqfCgW+towvu41nDp+f7LsxkkS8LsmvgF8Av4+Sp4DFVWusbF4Iy0dDmdsFKc7nyMsj2ZRxJ8dlXsThY+XMfjhULESEljieph2n/heYRt/pb0ftxuSa63qTJWYLQ1V/4f4dEOVlYtGYeWtqpVi4tJRSbit9lsPHyuMOcHaQ/SzZWAhE78ZY2L2mTbyl4UPinaiqi+reHCMpFBdETT6FfVXOhuzUNsx8bVvIpkIR2wzYgGeTJV6XxP+fczKOT8nb7vEA4F2cgMBGY6R1RyjOD0lSVZo9WLnc+67x91HCU7Sk0kP1iGYyo3xoyBSs7UaWWsRbGv5TABF5Heiuqrvc41OAvyTFOqNu2bzQ6Y4U5+Ojsj8aLbr3chWkTBjXbCEdZD87tQ0zyp2AOTZGkbp4WYfRyS8WLntwZk2MxkTYQGca4NPIloWzFYDTDVnm68ey0n4h1QRvkGykHl4E4y3Xd+QF9/hG4M3EmWTUNUUlZexedD/tCR3oFJT0GGIRi+zmzawLksJ42ZfkLhG5jspI4U+o6uLEmmXUFUs2FlJ4oISTda+zTtclvBty1/j7WK7xxQKguKQsEWYajQRPUcOBDcAhVX1TRFqKSLaqHqryLCPphLuof3OsnJ9/W0MC4ESLZ1HCU0iZBIL6xsK2B0htvGxk9AvgJeBxNykXWJJAm4waEs1F/bvH3qGb5NNB9gXGLKIFv/GH/4+HrbEwvHirjgT64kTaQlU/w9zbGyThLuqD0lYzPWMeGVJOmjhjFvEiZeXKvsDOZH7SRRCc1Zu2taHhpUtyTFVL/f9YItIMc29vkIS7qI9rtjAQ6dtLWD0RmJ4xD8qcGZKsjHQTCSMELy2Mf4rI/UCWiFwOvAgs91K5iOSIyEsi8qmIfOIGFg7OFxGZJSL/EZHN5tRWO8LHFzrEGLOomJRNCc2j1hHcNTGxMMLxIhj3AXuBLcAdwApgosf6HwNeVdVuwLlE7ph2FXCG+7od+LPHeo0ohPt27NS2qCrfH14Z9N03OZudnMT4stvQGO3EDrKf3JwsEwsjgriCISLpwCeq+qSq3qCq17vvq+ySiEhrnKnYpwBUtTQ41J/LtcBf1WEtkOOuJDVqwOCeuUwbcg65OVkI8Ee9MaIbclSaB1ZsFmrbqPXs1DY2uGlERap69kVkKTBKVXdUq2KRPOAJ4GOc1sV64G5V/SaozCvAdFVd7R6/BdynquvC6rodN8pXu3btes+fP786ptSKw4cP06pVq6RdL5iikjL2FB+ltMJHZnoa7Vq3AIhIy8nKiDi38MARbh5ydeD47Wf/gIiwn2x2aVsUyOEwubKPtKA9UH0qfJV2Mu3bNxzdrs/voC5ojPYPGDBgvar2CU/3Muh5AvCRiHwABB52VR1UxXnNcCJ1jVLV90XkMWA8MMm72YFrPYEjPvTp00f79+9f3SpqzMqVK0nm9fws2VjIhLe2UFKWhr8hmJFeBgplvsq0rIwKpg3pHtJ9UFXS0iobj28/9wcG/N8UwHEg+7Xezhvp36OopBmD0raG+IssPfFnjLzn7mTdpifq6zuoKxq7/cF4EYxqP+AuBUCBqr7vHr+EIxjBFAKdgo47umkpT7Qo3mUVka3BkrKKgLs5RIqFb3I2/wyaDWkppdyt85n569+6KVcD0wDnwx9Zp3dhNDXixcNogbNz+7dxBjyfUtVyrxWr6m4RyReRrqq6DbgUp3sSzDLgLhGZD1wAFIc5uqUs8aJ4xyobLhblk6JH9+5QRRBfw4hFvEHPZ4A+OGJxFdFD9VXFKOA5EdkM5AG/E5ERIjLCzV8BfA78B3gSuLMG12iSVGcJdoecrAix6DxuObs4KWr53dKm1vYZqUm8Lkl3VT0HQESeAj6obuWquglHdIKZG5SvWCs4KmOv6MqERVtCuiUZ6eKOYVR2TQQoOHAkQixEhBnlQ52FWEEc0UwKe4+jQ8LvwGiKxBOMgFuiqpZX5fZs1C2xwt/50wqLShDAF7ZvSHg8C8pgoDZzZj+kLfm9x3LeoDuSfj9G0yCeYJwrIgfd94Kz0vOg+15V9fiEW5fiRAt/5w/AC/HFws8yXz/OSvNx+W+KaA+0T6jFRlMnXoi+9Fh5Rv3g90YtKauIuiNZbtpwdmrbwMIscDxM27WOvfGQYVQHr/EwjFoQHqOiysjamxdy5B+TaVGym52+NszLvJm8q29nwqLNlJT5IsTi8KQ2HJfmzHx0lH08nPkUUgrrjr+csVd0Jaf4s0TfopEimGAkmOBWATgxKiYs2gIQXTQ2L6R86ShaVhwFoGPaPsaVzeH+l0opqegXtWXhFws/WRzjsZOWwxhnfcXKlSYYRt3gxfnMqAXRFmD5F1tF5a2pNHPFwk9LKeXe9IURYtF53HJy02KsqYix94hh1AYTjAQTawFWzIVZHjcZ8g9w7ozhQEbrjtWy0zC8YIKRYGItwIq5MCvKg+5sBXAwcBw8GzKjfGjkbuoZWXDp5JoZbBhxMMFIMF73H524ZAvfmrCC0XsHcixogipadO/gqdNlvn6ML7uNAp+zmzqtO8HAWdBjaILuyEhlbNAzwXjZf3Tiki08u9aJHrBM+zGFv9Kcw56je/s3HMrNyWLNGNsn20gcJhhJoKr9R194P3Sf05wYYiEitKSU6a0X88bh74UMplpEbyMZWJekAVARFsSo0NcmbsDeliW7QyJrWURvI1lYC6MBkC4SEA1VpfNDXwTyokX3pnVH2zXdqBeshdEAuPD0EwAi1lnsnXgKIfsbgs2AGPWKCUYDYPv+kqiLsvqUPcndZXfaDIjRYLAuSQOg8MCRuC7qy0qdGZHtY66Oer5hJAtrYdQzqsqXVbioG0ZDwQSjHokWVi+WWJiEGA0BE4x6Ilwshj2+Jm7LYviFnZNhlmHExQSjHojYCsDn4/nbL+bmCztHtCQEuPnCzjw0+Jyk2mgY0bBBzyQTTSz8LYuHBp9jwmA0aKyFkUTiiYVhNAZMMJKEiYXRFDDBSALhYnHquOX0e/idkAjghtEYMMFIMNGmThEJxPY00TAaEyYYCeSBxZvjrrOIG9vTMBogJhgJ4oHFm/ndkHMDx7EWZVVn02XDqG9MMBKAqnoSC6jepsuGUd+YYNQx1VnubVGyjMaGLdyqQ7yKhYC3HdAMo4FhglFHfLB0LhcM/mXg+E9/eJBH9kSKhS3zNhoz1iWpA8LFwjc5m58XPcbY9ptId1sY6SImFkajx1oYtURVI8RCRMiilB8V/S8jpz1Qj9YZRt1iLYxaELHcOyxg78m6rz7MMoyEYYJRQ6oSC4CvJMa+p4bRSDHBqAGLNxSEiMX8eTM5SvOQMiWaSX6vsck2zTASiglGNVm8oYAhvTsFjjuPW86U7Wez/NTx7OYkfCrs5iS29n6I8wbdUY+WGkbdY4Oe1UBVI8RCRCgpq+Cxr3oydMp/AGjvvgyjqWEtDI9UtSjLfEKMVMAEwwNeVnCaT4iRCiRUMERku4hsEZFNIrIuSn5/ESl28zeJSIPbAzBcLBatz6dlZmhPznxCjFQhGWMYA1TjLkhYparXJMGOarFkYyEzXv2U9+6/LJDmD6snIsx8bRs7i0rMJ8RIKWzQMwpLNhYy/uXNbPvtDwNpXR9YwdJNOwO7pptAGKmIqGriKhf5AjgAKPC4qj4Rlt8feBkoAHYC96rqR1HquR24HaBdu3a958+fnzCbAT7ddZBf/vjawPFjf1uMiJCZnkbX9tkJvXYiOHz4MK1atapvM2qM2Z98BgwYsF5V+4SnJ1owclW1UEROBt4ARqnqv4Lyjwd8qnpYRH4IPKaqZ8Srs0+fPrpuXcRwSJ0RPmbx2N8W84etGY69wBfTG9+GyCtXrqR///71bUaNMfuTj4hEFYyEDnqqaqH79ytgMXB+WP5BVT3svl8BZIjU33rqqmZDbCbESHUSJhgicpyIZPvfAz8AtoaVaS/uEyki57v27E+UTfEIF4uuD6wIEQubCTGMxA56tgMWuw9dM+B5VX1VREYAqOpc4HrglyJSDpQAN2ki+0gxiLbJ0NJNO92I3ofItZkQwwASKBiq+jlwbpT0uUHvZwOzE2WDF2LtSOafCVm5ciWjhvevPwMNowGR0is9bftCw6geKSsYJhaGUX1SUjBMLAyjZqScYJhYGEbNSSnBMLEwjNqRMoJhYmEYtafJOZ8t2VgY4Ul6bV4HEwvDqAOaVAtjycZCJizaQmFRCQoUFpUw/uXNJhaGUUc0KcGY+do2SsoqAseqGuKibmJhGLWjSQlGcFxNVWXHjIGBYxMLw6g9TUow/N6k4WJx0e/eNLEwjDqgSQnG2Cu6kpWRzs55IwJpXR9Ywbgru9WjVYbRdGhSsyR+b9KR/+rHV1vXcN69f2Hcld3My9Qw6ogmJRjgiMbgfyY2hJ9hpCpNqktiGEZiMcEwDMMzJhiGYXjGBMMwDM+YYBiG4RkTDMMwPGOCYRiGZ0wwDMPwTEK3SkwEIrIX+DKJl2wLxNt9vjHQ2O/B7E8+p6rqSeGJjU4wko2IrIu2x2RjorHfg9nfcLAuiWEYnjHBMAzDMyYYVfNEfRtQBzT2ezD7Gwg2hmEYhmeshWEYhmdMMAzD8IwJhouIbBeRLSKySUTWRcnvLyLFbv4mEZlcH3bGQkRyROQlEflURD4RkYvC8kVEZonIf0Rks4j0qi9bY+HhHhrsdyAiXYPs2iQiB0XknrAyDf47qIomF3GrlgxQ1XgLbFap6jVJs6Z6PAa8qqrXi0gm0DIs/yrgDPd1AfBn929Doqp7gAb6HajqNiAPQETSgUJgcVixxvAdxMVaGE0AEWkNfBd4CkBVS1W1KKzYtcBf1WEtkCMipyTX0th4vIfGwqXAf1U1fEVyg/4OvGCCUYkCr4vIehG5PUaZi0TkQxH5h4iclUzjquA0YC/wvyKyUUTmichxYWVygfyg4wI3raHg5R6g4X4HwdwEvBAlvaF/B1ViglFJP1XthdNsHCki3w3L34Czvv5c4E/AkiTbF49mQC/gz6raE/gGGF+/JlUbL/fQkL8DANyu1CDgxfq2JRGYYLioaqH79yucvuf5YfkHVfWw+34FkCEibZNuaHQKgAJVfd89fgnn4QumEOgUdNzRTWsoVHkPDfw78HMVsEFV90TJa+jfQZWYYAAicpyIZPvfAz8AtoaVaS/u9mkicj7OZ7c/2bZGQ1V3A/ki0tVNuhT4OKzYMuAWd6T+QqBYVXcl0854eLmHhvwdBDGM6N0RaODfgRdslsShHbDY/V9sBjyvqq+KyAgAVZ0LXA/8UkTKgRLgJm1Yy2RHAc+5TeLPgZ+G2b8C+CHwH+AI8NP6MjQOVd1Dg/4O3B+by4E7gtIa23cQF1sabhiGZ6xLYhiGZ0wwDMPwjAmGYRieMcEwDMMzJhiGYXjGBCPFEJHBIqIi0s1D2XtEJJoDmNdr/UREZoeldRGRAhFJC0vfJCJRHbHcc7ZGyzOSiwlG6jEMWO3+rYp7iO4xWmNUdTuwA7jEn+aKV3bQKk+jgWKCkUKISCugH/BzHAcpf3q6iDwiIlvdOA2jRGQ00AF4R0TeccsdDjrnehH5i/t+oIi87zqNvSki7aow5YXg67vv57stiVUissF9XRzlHkJaLSLyioj0d9//QETec8990b1fow4xwUgtrsWJN/F/wH4R6e2m3w50AfJUtQfwnKrOAnbixAgZUEW9q4ELXaex+cC4KsovBAaLiH+l8Y04IvIVcLnrBHgjMMvrjbk+JROBy9zz1wH/4/V8wxu2NDy1GIYTpAacB3sYsB64DJirquUAqvp1NevtCCxwYztkAl/EK6yqe9wxiUtFZA9Qrqpb3ZgYs0UkD6gAvlMNGy4EugNr3CX+mcB71bwPowpMMFIEETkR+D5wjogokA6oiIytRjXBfgQtgt7/CfiDqi5zuwdTPNTl75bsodJZa4x7fC5O6/dolPPKCW0Z++0Q4A1V9TI2Y9QQ65KkDtcDf1PVU1W1i6p2wmkJXAK8Adzh7yK44gJwCMgOqmOPiJzpznBcF5Temko37Vs92rMIxxHrRpzWjr+eXarqA/4fjqiFsx3IE5E0EelEZRiCtUBfEfm2ew/HiUh1WiiGB0wwUodhRMaYfNlNn4czc7FZRD4EfuzmPwG86h/0xAlo8wrwLhDslj0FeFFE1uNx02E3/N57wB5V/dxNngPc6trQDSeITjhrcITuY5wxjg1ufXuBnwAviMhmt+4qp46N6mHeqoZheMZaGIZheMYEwzAMz5hgGIbhGRMMwzA8Y4JhGIZnTDAMw/CMCYZhGJ75/x4lDrolC+DdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.scatter(target_train, test_run, label = 'Training Data')\n",
    "plt.scatter(target_test, predictions, label = 'Testing Data')\n",
    "plt.legend()\n",
    "plt.title(\"Actual Data vs Predicted Data\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.plot(target_train, target_train, 'k-')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
